// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"

	"github.com/open-telemetry/opentelemetry-collector-contrib/pkg/pdatautil"
)

// AttributeClass specifies the a value class attribute.
type AttributeClass int

const (
	_ AttributeClass = iota
	AttributeClassDatapath
	AttributeClassServices
)

// String returns the string representation of the AttributeClass.
func (av AttributeClass) String() string {
	switch av {
	case AttributeClassDatapath:
		return "datapath"
	case AttributeClassServices:
		return "services"
	}
	return ""
}

// MapAttributeClass is a helper map of string to AttributeClass attribute value.
var MapAttributeClass = map[string]AttributeClass{
	"datapath": AttributeClassDatapath,
	"services": AttributeClassServices,
}

// AttributeDirection specifies the a value direction attribute.
type AttributeDirection int

const (
	_ AttributeDirection = iota
	AttributeDirectionReceived
	AttributeDirectionTransmitted
)

// String returns the string representation of the AttributeDirection.
func (av AttributeDirection) String() string {
	switch av {
	case AttributeDirectionReceived:
		return "received"
	case AttributeDirectionTransmitted:
		return "transmitted"
	}
	return ""
}

// MapAttributeDirection is a helper map of string to AttributeDirection attribute value.
var MapAttributeDirection = map[string]AttributeDirection{
	"received":    AttributeDirectionReceived,
	"transmitted": AttributeDirectionTransmitted,
}

// AttributeDiskState specifies the a value disk_state attribute.
type AttributeDiskState int

const (
	_ AttributeDiskState = iota
	AttributeDiskStateUsed
	AttributeDiskStateAvailable
)

// String returns the string representation of the AttributeDiskState.
func (av AttributeDiskState) String() string {
	switch av {
	case AttributeDiskStateUsed:
		return "used"
	case AttributeDiskStateAvailable:
		return "available"
	}
	return ""
}

// MapAttributeDiskState is a helper map of string to AttributeDiskState attribute value.
var MapAttributeDiskState = map[string]AttributeDiskState{
	"used":      AttributeDiskStateUsed,
	"available": AttributeDiskStateAvailable,
}

// AttributePacketType specifies the a value packet.type attribute.
type AttributePacketType int

const (
	_ AttributePacketType = iota
	AttributePacketTypeDropped
	AttributePacketTypeErrored
	AttributePacketTypeSuccess
)

// String returns the string representation of the AttributePacketType.
func (av AttributePacketType) String() string {
	switch av {
	case AttributePacketTypeDropped:
		return "dropped"
	case AttributePacketTypeErrored:
		return "errored"
	case AttributePacketTypeSuccess:
		return "success"
	}
	return ""
}

// MapAttributePacketType is a helper map of string to AttributePacketType attribute value.
var MapAttributePacketType = map[string]AttributePacketType{
	"dropped": AttributePacketTypeDropped,
	"errored": AttributePacketTypeErrored,
	"success": AttributePacketTypeSuccess,
}

type metricNsxtNodeCPUUtilization struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nsxt.node.cpu.utilization metric with initial data.
func (m *metricNsxtNodeCPUUtilization) init() {
	m.data.SetName("nsxt.node.cpu.utilization")
	m.data.SetDescription("The average amount of CPU being used by the node.")
	m.data.SetUnit("%")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNsxtNodeCPUUtilization) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, classAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("class", classAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNsxtNodeCPUUtilization) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNsxtNodeCPUUtilization) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNsxtNodeCPUUtilization(cfg MetricConfig) metricNsxtNodeCPUUtilization {
	m := metricNsxtNodeCPUUtilization{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNsxtNodeFilesystemUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nsxt.node.filesystem.usage metric with initial data.
func (m *metricNsxtNodeFilesystemUsage) init() {
	m.data.SetName("nsxt.node.filesystem.usage")
	m.data.SetDescription("The amount of storage space used by the node.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNsxtNodeFilesystemUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, diskStateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("state", diskStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNsxtNodeFilesystemUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNsxtNodeFilesystemUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNsxtNodeFilesystemUsage(cfg MetricConfig) metricNsxtNodeFilesystemUsage {
	m := metricNsxtNodeFilesystemUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNsxtNodeFilesystemUtilization struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nsxt.node.filesystem.utilization metric with initial data.
func (m *metricNsxtNodeFilesystemUtilization) init() {
	m.data.SetName("nsxt.node.filesystem.utilization")
	m.data.SetDescription("The percentage of storage space utilized.")
	m.data.SetUnit("%")
	m.data.SetEmptyGauge()
}

func (m *metricNsxtNodeFilesystemUtilization) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNsxtNodeFilesystemUtilization) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNsxtNodeFilesystemUtilization) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNsxtNodeFilesystemUtilization(cfg MetricConfig) metricNsxtNodeFilesystemUtilization {
	m := metricNsxtNodeFilesystemUtilization{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNsxtNodeMemoryCacheUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nsxt.node.memory.cache.usage metric with initial data.
func (m *metricNsxtNodeMemoryCacheUsage) init() {
	m.data.SetName("nsxt.node.memory.cache.usage")
	m.data.SetDescription("The size of the node's memory cache.")
	m.data.SetUnit("KBy")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricNsxtNodeMemoryCacheUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNsxtNodeMemoryCacheUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNsxtNodeMemoryCacheUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNsxtNodeMemoryCacheUsage(cfg MetricConfig) metricNsxtNodeMemoryCacheUsage {
	m := metricNsxtNodeMemoryCacheUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNsxtNodeMemoryUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nsxt.node.memory.usage metric with initial data.
func (m *metricNsxtNodeMemoryUsage) init() {
	m.data.SetName("nsxt.node.memory.usage")
	m.data.SetDescription("The memory usage of the node.")
	m.data.SetUnit("KBy")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricNsxtNodeMemoryUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNsxtNodeMemoryUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNsxtNodeMemoryUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNsxtNodeMemoryUsage(cfg MetricConfig) metricNsxtNodeMemoryUsage {
	m := metricNsxtNodeMemoryUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNsxtNodeNetworkIo struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nsxt.node.network.io metric with initial data.
func (m *metricNsxtNodeNetworkIo) init() {
	m.data.SetName("nsxt.node.network.io")
	m.data.SetDescription("The number of bytes which have flowed through the network interface.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNsxtNodeNetworkIo) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNsxtNodeNetworkIo) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNsxtNodeNetworkIo) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNsxtNodeNetworkIo(cfg MetricConfig) metricNsxtNodeNetworkIo {
	m := metricNsxtNodeNetworkIo{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNsxtNodeNetworkPacketCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nsxt.node.network.packet.count metric with initial data.
func (m *metricNsxtNodeNetworkPacketCount) init() {
	m.data.SetName("nsxt.node.network.packet.count")
	m.data.SetDescription("The number of packets which have flowed through the network interface on the node.")
	m.data.SetUnit("{packets}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNsxtNodeNetworkPacketCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string, packetTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
	dp.Attributes().PutStr("type", packetTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNsxtNodeNetworkPacketCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNsxtNodeNetworkPacketCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNsxtNodeNetworkPacketCount(cfg MetricConfig) metricNsxtNodeNetworkPacketCount {
	m := metricNsxtNodeNetworkPacketCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// missedEmitsToDropRMB is number of missed emits after which resource builder will be dropped from MetricsBuilder.rmbMap.
// Potentially, this value can be made configurable through a MetricsBuilder option.
const missedEmitsToDropRMB = 5

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config    MetricsBuilderConfig                 // config of the metrics builder.
	buildInfo component.BuildInfo                  // contains version information
	startTime pcommon.Timestamp                    // start time that will be applied to all recorded data points.
	rmbMap    map[[16]byte]*ResourceMetricsBuilder // map of resource builders by resource hash.
}

type ResourceMetricsBuilder struct {
	buildInfo                           component.BuildInfo
	startTime                           pcommon.Timestamp // start time that will be applied to all recorded data points.
	metricsCapacity                     int               // maximum observed number of metrics per resource.
	resource                            pcommon.Resource
	missedEmits                         int
	metricNsxtNodeCPUUtilization        metricNsxtNodeCPUUtilization
	metricNsxtNodeFilesystemUsage       metricNsxtNodeFilesystemUsage
	metricNsxtNodeFilesystemUtilization metricNsxtNodeFilesystemUtilization
	metricNsxtNodeMemoryCacheUsage      metricNsxtNodeMemoryCacheUsage
	metricNsxtNodeMemoryUsage           metricNsxtNodeMemoryUsage
	metricNsxtNodeNetworkIo             metricNsxtNodeNetworkIo
	metricNsxtNodeNetworkPacketCount    metricNsxtNodeNetworkPacketCount
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.CreateSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:    mbc,
		startTime: pcommon.NewTimestampFromTime(time.Now()),
		buildInfo: settings.BuildInfo,
		rmbMap:    make(map[[16]byte]*ResourceMetricsBuilder),
	}
	for _, opt := range options {
		opt(mb)
	}
	return mb
}

// resourceMetricsBuilderOption applies changes to provided resource metrics.
type resourceMetricsBuilderOption func(*ResourceMetricsBuilder)

// WithStartTimeOverride sets start time for all the resource metrics data points.
func WithStartTimeOverride(start pcommon.Timestamp) resourceMetricsBuilderOption {
	return func(rmb *ResourceMetricsBuilder) {
		rmb.startTime = start
	}
}

// ResourceMetricsBuilder returns a ResourceMetricsBuilder that can be used to record metrics for a specific resource.
// It requires Resource to be provided which should be built with ResourceBuilder.
func (mb *MetricsBuilder) ResourceMetricsBuilder(res pcommon.Resource, options ...resourceMetricsBuilderOption) *ResourceMetricsBuilder {
	hash := pdatautil.MapHash(res.Attributes())
	if rmb, ok := mb.rmbMap[hash]; ok {
		return rmb
	}
	rmb := &ResourceMetricsBuilder{
		startTime:                           mb.startTime,
		buildInfo:                           mb.buildInfo,
		resource:                            res,
		metricNsxtNodeCPUUtilization:        newMetricNsxtNodeCPUUtilization(mb.config.Metrics.NsxtNodeCPUUtilization),
		metricNsxtNodeFilesystemUsage:       newMetricNsxtNodeFilesystemUsage(mb.config.Metrics.NsxtNodeFilesystemUsage),
		metricNsxtNodeFilesystemUtilization: newMetricNsxtNodeFilesystemUtilization(mb.config.Metrics.NsxtNodeFilesystemUtilization),
		metricNsxtNodeMemoryCacheUsage:      newMetricNsxtNodeMemoryCacheUsage(mb.config.Metrics.NsxtNodeMemoryCacheUsage),
		metricNsxtNodeMemoryUsage:           newMetricNsxtNodeMemoryUsage(mb.config.Metrics.NsxtNodeMemoryUsage),
		metricNsxtNodeNetworkIo:             newMetricNsxtNodeNetworkIo(mb.config.Metrics.NsxtNodeNetworkIo),
		metricNsxtNodeNetworkPacketCount:    newMetricNsxtNodeNetworkPacketCount(mb.config.Metrics.NsxtNodeNetworkPacketCount),
	}
	for _, op := range options {
		op(rmb)
	}
	mb.rmbMap[hash] = rmb
	return rmb
}

// NewResourceBuilder returns a new resource builder that should be used to build a resource associated with for the emitted metrics.
func (mb *MetricsBuilder) NewResourceBuilder() *ResourceBuilder {
	return NewResourceBuilder(mb.config.ResourceAttributes)
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (rmb *ResourceMetricsBuilder) updateCapacity(ms pmetric.MetricSlice) {
	if rmb.metricsCapacity < ms.Len() {
		rmb.metricsCapacity = ms.Len()
	}
}

// emit emits all the metrics accumulated by the ResourceMetricsBuilder and updates the internal state to be ready for
// recording another set of metrics. It returns true if any metrics were emitted.
func (rmb *ResourceMetricsBuilder) emit(m pmetric.Metrics) bool {
	sm := pmetric.NewScopeMetrics()
	sm.Metrics().EnsureCapacity(rmb.metricsCapacity)
	rmb.metricNsxtNodeCPUUtilization.emit(sm.Metrics())
	rmb.metricNsxtNodeFilesystemUsage.emit(sm.Metrics())
	rmb.metricNsxtNodeFilesystemUtilization.emit(sm.Metrics())
	rmb.metricNsxtNodeMemoryCacheUsage.emit(sm.Metrics())
	rmb.metricNsxtNodeMemoryUsage.emit(sm.Metrics())
	rmb.metricNsxtNodeNetworkIo.emit(sm.Metrics())
	rmb.metricNsxtNodeNetworkPacketCount.emit(sm.Metrics())
	if sm.Metrics().Len() == 0 {
		return false
	}
	rmb.updateCapacity(sm.Metrics())
	sm.Scope().SetName("otelcol/nsxtreceiver")
	sm.Scope().SetVersion(rmb.buildInfo.Version)
	rm := m.ResourceMetrics().AppendEmpty()
	rmb.resource.CopyTo(rm.Resource())
	sm.MoveTo(rm.ScopeMetrics().AppendEmpty())
	return true
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit() pmetric.Metrics {
	m := pmetric.NewMetrics()
	for _, rmb := range mb.rmbMap {
		if ok := rmb.emit(m); !ok {
			rmb.missedEmits++
		}
	}
	for k, rmb := range mb.rmbMap {
		if rmb.missedEmits >= missedEmitsToDropRMB {
			delete(mb.rmbMap, k)
		}
	}
	return m
}

// RecordNsxtNodeCPUUtilizationDataPoint adds a data point to nsxt.node.cpu.utilization metric.
func (rmb *ResourceMetricsBuilder) RecordNsxtNodeCPUUtilizationDataPoint(ts pcommon.Timestamp, val float64, classAttributeValue AttributeClass) {
	rmb.metricNsxtNodeCPUUtilization.recordDataPoint(rmb.startTime, ts, val, classAttributeValue.String())
}

// RecordNsxtNodeFilesystemUsageDataPoint adds a data point to nsxt.node.filesystem.usage metric.
func (rmb *ResourceMetricsBuilder) RecordNsxtNodeFilesystemUsageDataPoint(ts pcommon.Timestamp, val int64, diskStateAttributeValue AttributeDiskState) {
	rmb.metricNsxtNodeFilesystemUsage.recordDataPoint(rmb.startTime, ts, val, diskStateAttributeValue.String())
}

// RecordNsxtNodeFilesystemUtilizationDataPoint adds a data point to nsxt.node.filesystem.utilization metric.
func (rmb *ResourceMetricsBuilder) RecordNsxtNodeFilesystemUtilizationDataPoint(ts pcommon.Timestamp, val float64) {
	rmb.metricNsxtNodeFilesystemUtilization.recordDataPoint(rmb.startTime, ts, val)
}

// RecordNsxtNodeMemoryCacheUsageDataPoint adds a data point to nsxt.node.memory.cache.usage metric.
func (rmb *ResourceMetricsBuilder) RecordNsxtNodeMemoryCacheUsageDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricNsxtNodeMemoryCacheUsage.recordDataPoint(rmb.startTime, ts, val)
}

// RecordNsxtNodeMemoryUsageDataPoint adds a data point to nsxt.node.memory.usage metric.
func (rmb *ResourceMetricsBuilder) RecordNsxtNodeMemoryUsageDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricNsxtNodeMemoryUsage.recordDataPoint(rmb.startTime, ts, val)
}

// RecordNsxtNodeNetworkIoDataPoint adds a data point to nsxt.node.network.io metric.
func (rmb *ResourceMetricsBuilder) RecordNsxtNodeNetworkIoDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	rmb.metricNsxtNodeNetworkIo.recordDataPoint(rmb.startTime, ts, val, directionAttributeValue.String())
}

// RecordNsxtNodeNetworkPacketCountDataPoint adds a data point to nsxt.node.network.packet.count metric.
func (rmb *ResourceMetricsBuilder) RecordNsxtNodeNetworkPacketCountDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection, packetTypeAttributeValue AttributePacketType) {
	rmb.metricNsxtNodeNetworkPacketCount.recordDataPoint(rmb.startTime, ts, val, directionAttributeValue.String(), packetTypeAttributeValue.String())
}

// Reset resets the ResourceMetricsBuilder to its initial state. It should be used when external metrics source is
// restarted, and the ResourceMetricsBuilder should update its startTime and reset it's internal state accordingly.
func (rmb *ResourceMetricsBuilder) Reset(options ...resourceMetricsBuilderOption) {
	rmb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(rmb)
	}
}
