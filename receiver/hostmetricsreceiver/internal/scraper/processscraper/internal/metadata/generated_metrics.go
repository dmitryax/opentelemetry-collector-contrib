// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
	conventions "go.opentelemetry.io/collector/semconv/v1.9.0"

	"github.com/open-telemetry/opentelemetry-collector-contrib/pkg/pdatautil"
)

// AttributeContextSwitchType specifies the a value context_switch_type attribute.
type AttributeContextSwitchType int

const (
	_ AttributeContextSwitchType = iota
	AttributeContextSwitchTypeInvoluntary
	AttributeContextSwitchTypeVoluntary
)

// String returns the string representation of the AttributeContextSwitchType.
func (av AttributeContextSwitchType) String() string {
	switch av {
	case AttributeContextSwitchTypeInvoluntary:
		return "involuntary"
	case AttributeContextSwitchTypeVoluntary:
		return "voluntary"
	}
	return ""
}

// MapAttributeContextSwitchType is a helper map of string to AttributeContextSwitchType attribute value.
var MapAttributeContextSwitchType = map[string]AttributeContextSwitchType{
	"involuntary": AttributeContextSwitchTypeInvoluntary,
	"voluntary":   AttributeContextSwitchTypeVoluntary,
}

// AttributeDirection specifies the a value direction attribute.
type AttributeDirection int

const (
	_ AttributeDirection = iota
	AttributeDirectionRead
	AttributeDirectionWrite
)

// String returns the string representation of the AttributeDirection.
func (av AttributeDirection) String() string {
	switch av {
	case AttributeDirectionRead:
		return "read"
	case AttributeDirectionWrite:
		return "write"
	}
	return ""
}

// MapAttributeDirection is a helper map of string to AttributeDirection attribute value.
var MapAttributeDirection = map[string]AttributeDirection{
	"read":  AttributeDirectionRead,
	"write": AttributeDirectionWrite,
}

// AttributePagingFaultType specifies the a value paging_fault_type attribute.
type AttributePagingFaultType int

const (
	_ AttributePagingFaultType = iota
	AttributePagingFaultTypeMajor
	AttributePagingFaultTypeMinor
)

// String returns the string representation of the AttributePagingFaultType.
func (av AttributePagingFaultType) String() string {
	switch av {
	case AttributePagingFaultTypeMajor:
		return "major"
	case AttributePagingFaultTypeMinor:
		return "minor"
	}
	return ""
}

// MapAttributePagingFaultType is a helper map of string to AttributePagingFaultType attribute value.
var MapAttributePagingFaultType = map[string]AttributePagingFaultType{
	"major": AttributePagingFaultTypeMajor,
	"minor": AttributePagingFaultTypeMinor,
}

// AttributeState specifies the a value state attribute.
type AttributeState int

const (
	_ AttributeState = iota
	AttributeStateSystem
	AttributeStateUser
	AttributeStateWait
)

// String returns the string representation of the AttributeState.
func (av AttributeState) String() string {
	switch av {
	case AttributeStateSystem:
		return "system"
	case AttributeStateUser:
		return "user"
	case AttributeStateWait:
		return "wait"
	}
	return ""
}

// MapAttributeState is a helper map of string to AttributeState attribute value.
var MapAttributeState = map[string]AttributeState{
	"system": AttributeStateSystem,
	"user":   AttributeStateUser,
	"wait":   AttributeStateWait,
}

type metricProcessContextSwitches struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills process.context_switches metric with initial data.
func (m *metricProcessContextSwitches) init() {
	m.data.SetName("process.context_switches")
	m.data.SetDescription("Number of times the process has been context switched.")
	m.data.SetUnit("{count}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricProcessContextSwitches) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, contextSwitchTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("type", contextSwitchTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricProcessContextSwitches) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricProcessContextSwitches) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricProcessContextSwitches(cfg MetricConfig) metricProcessContextSwitches {
	m := metricProcessContextSwitches{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricProcessCPUTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills process.cpu.time metric with initial data.
func (m *metricProcessCPUTime) init() {
	m.data.SetName("process.cpu.time")
	m.data.SetDescription("Total CPU seconds broken down by different states.")
	m.data.SetUnit("s")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricProcessCPUTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, stateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("state", stateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricProcessCPUTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricProcessCPUTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricProcessCPUTime(cfg MetricConfig) metricProcessCPUTime {
	m := metricProcessCPUTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricProcessCPUUtilization struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills process.cpu.utilization metric with initial data.
func (m *metricProcessCPUUtilization) init() {
	m.data.SetName("process.cpu.utilization")
	m.data.SetDescription("Percentage of total CPU time used by the process since last scrape, expressed as a value between 0 and 1. On the first scrape, no data point is emitted for this metric.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricProcessCPUUtilization) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, stateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("state", stateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricProcessCPUUtilization) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricProcessCPUUtilization) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricProcessCPUUtilization(cfg MetricConfig) metricProcessCPUUtilization {
	m := metricProcessCPUUtilization{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricProcessDiskIo struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills process.disk.io metric with initial data.
func (m *metricProcessDiskIo) init() {
	m.data.SetName("process.disk.io")
	m.data.SetDescription("Disk bytes transferred.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricProcessDiskIo) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricProcessDiskIo) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricProcessDiskIo) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricProcessDiskIo(cfg MetricConfig) metricProcessDiskIo {
	m := metricProcessDiskIo{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricProcessDiskOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills process.disk.operations metric with initial data.
func (m *metricProcessDiskOperations) init() {
	m.data.SetName("process.disk.operations")
	m.data.SetDescription("Number of disk operations performed by the process.")
	m.data.SetUnit("{operations}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricProcessDiskOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricProcessDiskOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricProcessDiskOperations) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricProcessDiskOperations(cfg MetricConfig) metricProcessDiskOperations {
	m := metricProcessDiskOperations{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricProcessHandles struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills process.handles metric with initial data.
func (m *metricProcessHandles) init() {
	m.data.SetName("process.handles")
	m.data.SetDescription("Number of handles held by the process.")
	m.data.SetUnit("{count}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricProcessHandles) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricProcessHandles) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricProcessHandles) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricProcessHandles(cfg MetricConfig) metricProcessHandles {
	m := metricProcessHandles{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricProcessMemoryUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills process.memory.usage metric with initial data.
func (m *metricProcessMemoryUsage) init() {
	m.data.SetName("process.memory.usage")
	m.data.SetDescription("The amount of physical memory in use.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricProcessMemoryUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricProcessMemoryUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricProcessMemoryUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricProcessMemoryUsage(cfg MetricConfig) metricProcessMemoryUsage {
	m := metricProcessMemoryUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricProcessMemoryUtilization struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills process.memory.utilization metric with initial data.
func (m *metricProcessMemoryUtilization) init() {
	m.data.SetName("process.memory.utilization")
	m.data.SetDescription("Percentage of total physical memory that is used by the process.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
}

func (m *metricProcessMemoryUtilization) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricProcessMemoryUtilization) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricProcessMemoryUtilization) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricProcessMemoryUtilization(cfg MetricConfig) metricProcessMemoryUtilization {
	m := metricProcessMemoryUtilization{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricProcessMemoryVirtual struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills process.memory.virtual metric with initial data.
func (m *metricProcessMemoryVirtual) init() {
	m.data.SetName("process.memory.virtual")
	m.data.SetDescription("Virtual memory size.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricProcessMemoryVirtual) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricProcessMemoryVirtual) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricProcessMemoryVirtual) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricProcessMemoryVirtual(cfg MetricConfig) metricProcessMemoryVirtual {
	m := metricProcessMemoryVirtual{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricProcessOpenFileDescriptors struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills process.open_file_descriptors metric with initial data.
func (m *metricProcessOpenFileDescriptors) init() {
	m.data.SetName("process.open_file_descriptors")
	m.data.SetDescription("Number of file descriptors in use by the process.")
	m.data.SetUnit("{count}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricProcessOpenFileDescriptors) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricProcessOpenFileDescriptors) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricProcessOpenFileDescriptors) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricProcessOpenFileDescriptors(cfg MetricConfig) metricProcessOpenFileDescriptors {
	m := metricProcessOpenFileDescriptors{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricProcessPagingFaults struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills process.paging.faults metric with initial data.
func (m *metricProcessPagingFaults) init() {
	m.data.SetName("process.paging.faults")
	m.data.SetDescription("Number of page faults the process has made.")
	m.data.SetUnit("{faults}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricProcessPagingFaults) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, pagingFaultTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("type", pagingFaultTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricProcessPagingFaults) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricProcessPagingFaults) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricProcessPagingFaults(cfg MetricConfig) metricProcessPagingFaults {
	m := metricProcessPagingFaults{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricProcessSignalsPending struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills process.signals_pending metric with initial data.
func (m *metricProcessSignalsPending) init() {
	m.data.SetName("process.signals_pending")
	m.data.SetDescription("Number of pending signals for the process.")
	m.data.SetUnit("{signals}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricProcessSignalsPending) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricProcessSignalsPending) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricProcessSignalsPending) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricProcessSignalsPending(cfg MetricConfig) metricProcessSignalsPending {
	m := metricProcessSignalsPending{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricProcessThreads struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills process.threads metric with initial data.
func (m *metricProcessThreads) init() {
	m.data.SetName("process.threads")
	m.data.SetDescription("Process threads count.")
	m.data.SetUnit("{threads}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricProcessThreads) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricProcessThreads) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricProcessThreads) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricProcessThreads(cfg MetricConfig) metricProcessThreads {
	m := metricProcessThreads{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// missedEmitsToDropRMB is number of missed emits after which resource builder will be dropped from MetricsBuilder.rmbMap.
// Potentially, this value can be made configurable through a MetricsBuilder option.
const missedEmitsToDropRMB = 5

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config    MetricsBuilderConfig                 // config of the metrics builder.
	buildInfo component.BuildInfo                  // contains version information
	startTime pcommon.Timestamp                    // start time that will be applied to all recorded data points.
	rmbMap    map[[16]byte]*ResourceMetricsBuilder // map of resource builders by resource hash.
}

type ResourceMetricsBuilder struct {
	buildInfo                        component.BuildInfo
	startTime                        pcommon.Timestamp // start time that will be applied to all recorded data points.
	metricsCapacity                  int               // maximum observed number of metrics per resource.
	resource                         pcommon.Resource
	missedEmits                      int
	metricProcessContextSwitches     metricProcessContextSwitches
	metricProcessCPUTime             metricProcessCPUTime
	metricProcessCPUUtilization      metricProcessCPUUtilization
	metricProcessDiskIo              metricProcessDiskIo
	metricProcessDiskOperations      metricProcessDiskOperations
	metricProcessHandles             metricProcessHandles
	metricProcessMemoryUsage         metricProcessMemoryUsage
	metricProcessMemoryUtilization   metricProcessMemoryUtilization
	metricProcessMemoryVirtual       metricProcessMemoryVirtual
	metricProcessOpenFileDescriptors metricProcessOpenFileDescriptors
	metricProcessPagingFaults        metricProcessPagingFaults
	metricProcessSignalsPending      metricProcessSignalsPending
	metricProcessThreads             metricProcessThreads
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.CreateSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:    mbc,
		startTime: pcommon.NewTimestampFromTime(time.Now()),
		buildInfo: settings.BuildInfo,
		rmbMap:    make(map[[16]byte]*ResourceMetricsBuilder),
	}
	for _, opt := range options {
		opt(mb)
	}
	return mb
}

// resourceMetricsBuilderOption applies changes to provided resource metrics.
type resourceMetricsBuilderOption func(*ResourceMetricsBuilder)

// WithStartTimeOverride sets start time for all the resource metrics data points.
func WithStartTimeOverride(start pcommon.Timestamp) resourceMetricsBuilderOption {
	return func(rmb *ResourceMetricsBuilder) {
		rmb.startTime = start
	}
}

// ResourceMetricsBuilder returns a ResourceMetricsBuilder that can be used to record metrics for a specific resource.
// It requires Resource to be provided which should be built with ResourceBuilder.
func (mb *MetricsBuilder) ResourceMetricsBuilder(res pcommon.Resource, options ...resourceMetricsBuilderOption) *ResourceMetricsBuilder {
	hash := pdatautil.MapHash(res.Attributes())
	if rmb, ok := mb.rmbMap[hash]; ok {
		return rmb
	}
	rmb := &ResourceMetricsBuilder{
		startTime:                        mb.startTime,
		buildInfo:                        mb.buildInfo,
		resource:                         res,
		metricProcessContextSwitches:     newMetricProcessContextSwitches(mb.config.Metrics.ProcessContextSwitches),
		metricProcessCPUTime:             newMetricProcessCPUTime(mb.config.Metrics.ProcessCPUTime),
		metricProcessCPUUtilization:      newMetricProcessCPUUtilization(mb.config.Metrics.ProcessCPUUtilization),
		metricProcessDiskIo:              newMetricProcessDiskIo(mb.config.Metrics.ProcessDiskIo),
		metricProcessDiskOperations:      newMetricProcessDiskOperations(mb.config.Metrics.ProcessDiskOperations),
		metricProcessHandles:             newMetricProcessHandles(mb.config.Metrics.ProcessHandles),
		metricProcessMemoryUsage:         newMetricProcessMemoryUsage(mb.config.Metrics.ProcessMemoryUsage),
		metricProcessMemoryUtilization:   newMetricProcessMemoryUtilization(mb.config.Metrics.ProcessMemoryUtilization),
		metricProcessMemoryVirtual:       newMetricProcessMemoryVirtual(mb.config.Metrics.ProcessMemoryVirtual),
		metricProcessOpenFileDescriptors: newMetricProcessOpenFileDescriptors(mb.config.Metrics.ProcessOpenFileDescriptors),
		metricProcessPagingFaults:        newMetricProcessPagingFaults(mb.config.Metrics.ProcessPagingFaults),
		metricProcessSignalsPending:      newMetricProcessSignalsPending(mb.config.Metrics.ProcessSignalsPending),
		metricProcessThreads:             newMetricProcessThreads(mb.config.Metrics.ProcessThreads),
	}
	for _, op := range options {
		op(rmb)
	}
	mb.rmbMap[hash] = rmb
	return rmb
}

// NewResourceBuilder returns a new resource builder that should be used to build a resource associated with for the emitted metrics.
func (mb *MetricsBuilder) NewResourceBuilder() *ResourceBuilder {
	return NewResourceBuilder(mb.config.ResourceAttributes)
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (rmb *ResourceMetricsBuilder) updateCapacity(ms pmetric.MetricSlice) {
	if rmb.metricsCapacity < ms.Len() {
		rmb.metricsCapacity = ms.Len()
	}
}

// emit emits all the metrics accumulated by the ResourceMetricsBuilder and updates the internal state to be ready for
// recording another set of metrics. It returns true if any metrics were emitted.
func (rmb *ResourceMetricsBuilder) emit(m pmetric.Metrics) bool {
	sm := pmetric.NewScopeMetrics()
	sm.Metrics().EnsureCapacity(rmb.metricsCapacity)
	rmb.metricProcessContextSwitches.emit(sm.Metrics())
	rmb.metricProcessCPUTime.emit(sm.Metrics())
	rmb.metricProcessCPUUtilization.emit(sm.Metrics())
	rmb.metricProcessDiskIo.emit(sm.Metrics())
	rmb.metricProcessDiskOperations.emit(sm.Metrics())
	rmb.metricProcessHandles.emit(sm.Metrics())
	rmb.metricProcessMemoryUsage.emit(sm.Metrics())
	rmb.metricProcessMemoryUtilization.emit(sm.Metrics())
	rmb.metricProcessMemoryVirtual.emit(sm.Metrics())
	rmb.metricProcessOpenFileDescriptors.emit(sm.Metrics())
	rmb.metricProcessPagingFaults.emit(sm.Metrics())
	rmb.metricProcessSignalsPending.emit(sm.Metrics())
	rmb.metricProcessThreads.emit(sm.Metrics())
	if sm.Metrics().Len() == 0 {
		return false
	}
	rmb.updateCapacity(sm.Metrics())
	sm.Scope().SetName("otelcol/hostmetricsreceiver/process")
	sm.Scope().SetVersion(rmb.buildInfo.Version)
	rm := m.ResourceMetrics().AppendEmpty()
	rm.SetSchemaUrl(conventions.SchemaURL)
	rmb.resource.CopyTo(rm.Resource())
	sm.MoveTo(rm.ScopeMetrics().AppendEmpty())
	return true
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit() pmetric.Metrics {
	m := pmetric.NewMetrics()
	for _, rmb := range mb.rmbMap {
		if ok := rmb.emit(m); !ok {
			rmb.missedEmits++
		}
	}
	for k, rmb := range mb.rmbMap {
		if rmb.missedEmits >= missedEmitsToDropRMB {
			delete(mb.rmbMap, k)
		}
	}
	return m
}

// RecordProcessContextSwitchesDataPoint adds a data point to process.context_switches metric.
func (rmb *ResourceMetricsBuilder) RecordProcessContextSwitchesDataPoint(ts pcommon.Timestamp, val int64, contextSwitchTypeAttributeValue AttributeContextSwitchType) {
	rmb.metricProcessContextSwitches.recordDataPoint(rmb.startTime, ts, val, contextSwitchTypeAttributeValue.String())
}

// RecordProcessCPUTimeDataPoint adds a data point to process.cpu.time metric.
func (rmb *ResourceMetricsBuilder) RecordProcessCPUTimeDataPoint(ts pcommon.Timestamp, val float64, stateAttributeValue AttributeState) {
	rmb.metricProcessCPUTime.recordDataPoint(rmb.startTime, ts, val, stateAttributeValue.String())
}

// RecordProcessCPUUtilizationDataPoint adds a data point to process.cpu.utilization metric.
func (rmb *ResourceMetricsBuilder) RecordProcessCPUUtilizationDataPoint(ts pcommon.Timestamp, val float64, stateAttributeValue AttributeState) {
	rmb.metricProcessCPUUtilization.recordDataPoint(rmb.startTime, ts, val, stateAttributeValue.String())
}

// RecordProcessDiskIoDataPoint adds a data point to process.disk.io metric.
func (rmb *ResourceMetricsBuilder) RecordProcessDiskIoDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	rmb.metricProcessDiskIo.recordDataPoint(rmb.startTime, ts, val, directionAttributeValue.String())
}

// RecordProcessDiskOperationsDataPoint adds a data point to process.disk.operations metric.
func (rmb *ResourceMetricsBuilder) RecordProcessDiskOperationsDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	rmb.metricProcessDiskOperations.recordDataPoint(rmb.startTime, ts, val, directionAttributeValue.String())
}

// RecordProcessHandlesDataPoint adds a data point to process.handles metric.
func (rmb *ResourceMetricsBuilder) RecordProcessHandlesDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricProcessHandles.recordDataPoint(rmb.startTime, ts, val)
}

// RecordProcessMemoryUsageDataPoint adds a data point to process.memory.usage metric.
func (rmb *ResourceMetricsBuilder) RecordProcessMemoryUsageDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricProcessMemoryUsage.recordDataPoint(rmb.startTime, ts, val)
}

// RecordProcessMemoryUtilizationDataPoint adds a data point to process.memory.utilization metric.
func (rmb *ResourceMetricsBuilder) RecordProcessMemoryUtilizationDataPoint(ts pcommon.Timestamp, val float64) {
	rmb.metricProcessMemoryUtilization.recordDataPoint(rmb.startTime, ts, val)
}

// RecordProcessMemoryVirtualDataPoint adds a data point to process.memory.virtual metric.
func (rmb *ResourceMetricsBuilder) RecordProcessMemoryVirtualDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricProcessMemoryVirtual.recordDataPoint(rmb.startTime, ts, val)
}

// RecordProcessOpenFileDescriptorsDataPoint adds a data point to process.open_file_descriptors metric.
func (rmb *ResourceMetricsBuilder) RecordProcessOpenFileDescriptorsDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricProcessOpenFileDescriptors.recordDataPoint(rmb.startTime, ts, val)
}

// RecordProcessPagingFaultsDataPoint adds a data point to process.paging.faults metric.
func (rmb *ResourceMetricsBuilder) RecordProcessPagingFaultsDataPoint(ts pcommon.Timestamp, val int64, pagingFaultTypeAttributeValue AttributePagingFaultType) {
	rmb.metricProcessPagingFaults.recordDataPoint(rmb.startTime, ts, val, pagingFaultTypeAttributeValue.String())
}

// RecordProcessSignalsPendingDataPoint adds a data point to process.signals_pending metric.
func (rmb *ResourceMetricsBuilder) RecordProcessSignalsPendingDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricProcessSignalsPending.recordDataPoint(rmb.startTime, ts, val)
}

// RecordProcessThreadsDataPoint adds a data point to process.threads metric.
func (rmb *ResourceMetricsBuilder) RecordProcessThreadsDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricProcessThreads.recordDataPoint(rmb.startTime, ts, val)
}

// Reset resets the ResourceMetricsBuilder to its initial state. It should be used when external metrics source is
// restarted, and the ResourceMetricsBuilder should update its startTime and reset it's internal state accordingly.
func (rmb *ResourceMetricsBuilder) Reset(options ...resourceMetricsBuilderOption) {
	rmb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(rmb)
	}
}
