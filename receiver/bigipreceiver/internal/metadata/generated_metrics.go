// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"

	"github.com/open-telemetry/opentelemetry-collector-contrib/pkg/pdatautil"
)

// AttributeActiveStatus specifies the a value active.status attribute.
type AttributeActiveStatus int

const (
	_ AttributeActiveStatus = iota
	AttributeActiveStatusActive
	AttributeActiveStatusInactive
)

// String returns the string representation of the AttributeActiveStatus.
func (av AttributeActiveStatus) String() string {
	switch av {
	case AttributeActiveStatusActive:
		return "active"
	case AttributeActiveStatusInactive:
		return "inactive"
	}
	return ""
}

// MapAttributeActiveStatus is a helper map of string to AttributeActiveStatus attribute value.
var MapAttributeActiveStatus = map[string]AttributeActiveStatus{
	"active":   AttributeActiveStatusActive,
	"inactive": AttributeActiveStatusInactive,
}

// AttributeAvailabilityStatus specifies the a value availability.status attribute.
type AttributeAvailabilityStatus int

const (
	_ AttributeAvailabilityStatus = iota
	AttributeAvailabilityStatusOffline
	AttributeAvailabilityStatusUnknown
	AttributeAvailabilityStatusAvailable
)

// String returns the string representation of the AttributeAvailabilityStatus.
func (av AttributeAvailabilityStatus) String() string {
	switch av {
	case AttributeAvailabilityStatusOffline:
		return "offline"
	case AttributeAvailabilityStatusUnknown:
		return "unknown"
	case AttributeAvailabilityStatusAvailable:
		return "available"
	}
	return ""
}

// MapAttributeAvailabilityStatus is a helper map of string to AttributeAvailabilityStatus attribute value.
var MapAttributeAvailabilityStatus = map[string]AttributeAvailabilityStatus{
	"offline":   AttributeAvailabilityStatusOffline,
	"unknown":   AttributeAvailabilityStatusUnknown,
	"available": AttributeAvailabilityStatusAvailable,
}

// AttributeDirection specifies the a value direction attribute.
type AttributeDirection int

const (
	_ AttributeDirection = iota
	AttributeDirectionSent
	AttributeDirectionReceived
)

// String returns the string representation of the AttributeDirection.
func (av AttributeDirection) String() string {
	switch av {
	case AttributeDirectionSent:
		return "sent"
	case AttributeDirectionReceived:
		return "received"
	}
	return ""
}

// MapAttributeDirection is a helper map of string to AttributeDirection attribute value.
var MapAttributeDirection = map[string]AttributeDirection{
	"sent":     AttributeDirectionSent,
	"received": AttributeDirectionReceived,
}

// AttributeEnabledStatus specifies the a value enabled.status attribute.
type AttributeEnabledStatus int

const (
	_ AttributeEnabledStatus = iota
	AttributeEnabledStatusDisabled
	AttributeEnabledStatusEnabled
)

// String returns the string representation of the AttributeEnabledStatus.
func (av AttributeEnabledStatus) String() string {
	switch av {
	case AttributeEnabledStatusDisabled:
		return "disabled"
	case AttributeEnabledStatusEnabled:
		return "enabled"
	}
	return ""
}

// MapAttributeEnabledStatus is a helper map of string to AttributeEnabledStatus attribute value.
var MapAttributeEnabledStatus = map[string]AttributeEnabledStatus{
	"disabled": AttributeEnabledStatusDisabled,
	"enabled":  AttributeEnabledStatusEnabled,
}

type metricBigipNodeAvailability struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.node.availability metric with initial data.
func (m *metricBigipNodeAvailability) init() {
	m.data.SetName("bigip.node.availability")
	m.data.SetDescription("Availability of the node.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipNodeAvailability) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, availabilityStatusAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("status", availabilityStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipNodeAvailability) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipNodeAvailability) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipNodeAvailability(cfg MetricConfig) metricBigipNodeAvailability {
	m := metricBigipNodeAvailability{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipNodeConnectionCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.node.connection.count metric with initial data.
func (m *metricBigipNodeConnectionCount) init() {
	m.data.SetName("bigip.node.connection.count")
	m.data.SetDescription("Current number of connections to the node.")
	m.data.SetUnit("{connections}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricBigipNodeConnectionCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipNodeConnectionCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipNodeConnectionCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipNodeConnectionCount(cfg MetricConfig) metricBigipNodeConnectionCount {
	m := metricBigipNodeConnectionCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipNodeDataTransmitted struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.node.data.transmitted metric with initial data.
func (m *metricBigipNodeDataTransmitted) init() {
	m.data.SetName("bigip.node.data.transmitted")
	m.data.SetDescription("Amount of data transmitted to and from the node.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipNodeDataTransmitted) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipNodeDataTransmitted) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipNodeDataTransmitted) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipNodeDataTransmitted(cfg MetricConfig) metricBigipNodeDataTransmitted {
	m := metricBigipNodeDataTransmitted{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipNodeEnabled struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.node.enabled metric with initial data.
func (m *metricBigipNodeEnabled) init() {
	m.data.SetName("bigip.node.enabled")
	m.data.SetDescription("Enabled state of of the node.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipNodeEnabled) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, enabledStatusAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("status", enabledStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipNodeEnabled) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipNodeEnabled) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipNodeEnabled(cfg MetricConfig) metricBigipNodeEnabled {
	m := metricBigipNodeEnabled{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipNodePacketCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.node.packet.count metric with initial data.
func (m *metricBigipNodePacketCount) init() {
	m.data.SetName("bigip.node.packet.count")
	m.data.SetDescription("Number of packets transmitted to and from the node.")
	m.data.SetUnit("{packets}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipNodePacketCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipNodePacketCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipNodePacketCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipNodePacketCount(cfg MetricConfig) metricBigipNodePacketCount {
	m := metricBigipNodePacketCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipNodeRequestCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.node.request.count metric with initial data.
func (m *metricBigipNodeRequestCount) init() {
	m.data.SetName("bigip.node.request.count")
	m.data.SetDescription("Number of requests to the node.")
	m.data.SetUnit("{requests}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricBigipNodeRequestCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipNodeRequestCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipNodeRequestCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipNodeRequestCount(cfg MetricConfig) metricBigipNodeRequestCount {
	m := metricBigipNodeRequestCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipNodeSessionCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.node.session.count metric with initial data.
func (m *metricBigipNodeSessionCount) init() {
	m.data.SetName("bigip.node.session.count")
	m.data.SetDescription("Current number of sessions for the node.")
	m.data.SetUnit("{sessions}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricBigipNodeSessionCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipNodeSessionCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipNodeSessionCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipNodeSessionCount(cfg MetricConfig) metricBigipNodeSessionCount {
	m := metricBigipNodeSessionCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipPoolAvailability struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.pool.availability metric with initial data.
func (m *metricBigipPoolAvailability) init() {
	m.data.SetName("bigip.pool.availability")
	m.data.SetDescription("Availability of the pool.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipPoolAvailability) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, availabilityStatusAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("status", availabilityStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipPoolAvailability) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipPoolAvailability) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipPoolAvailability(cfg MetricConfig) metricBigipPoolAvailability {
	m := metricBigipPoolAvailability{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipPoolConnectionCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.pool.connection.count metric with initial data.
func (m *metricBigipPoolConnectionCount) init() {
	m.data.SetName("bigip.pool.connection.count")
	m.data.SetDescription("Current number of connections to the pool.")
	m.data.SetUnit("{connections}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricBigipPoolConnectionCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipPoolConnectionCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipPoolConnectionCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipPoolConnectionCount(cfg MetricConfig) metricBigipPoolConnectionCount {
	m := metricBigipPoolConnectionCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipPoolDataTransmitted struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.pool.data.transmitted metric with initial data.
func (m *metricBigipPoolDataTransmitted) init() {
	m.data.SetName("bigip.pool.data.transmitted")
	m.data.SetDescription("Amount of data transmitted to and from the pool.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipPoolDataTransmitted) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipPoolDataTransmitted) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipPoolDataTransmitted) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipPoolDataTransmitted(cfg MetricConfig) metricBigipPoolDataTransmitted {
	m := metricBigipPoolDataTransmitted{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipPoolEnabled struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.pool.enabled metric with initial data.
func (m *metricBigipPoolEnabled) init() {
	m.data.SetName("bigip.pool.enabled")
	m.data.SetDescription("Enabled state of of the pool.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipPoolEnabled) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, enabledStatusAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("status", enabledStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipPoolEnabled) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipPoolEnabled) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipPoolEnabled(cfg MetricConfig) metricBigipPoolEnabled {
	m := metricBigipPoolEnabled{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipPoolMemberCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.pool.member.count metric with initial data.
func (m *metricBigipPoolMemberCount) init() {
	m.data.SetName("bigip.pool.member.count")
	m.data.SetDescription("Total number of pool members.")
	m.data.SetUnit("{members}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipPoolMemberCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, activeStatusAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("status", activeStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipPoolMemberCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipPoolMemberCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipPoolMemberCount(cfg MetricConfig) metricBigipPoolMemberCount {
	m := metricBigipPoolMemberCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipPoolPacketCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.pool.packet.count metric with initial data.
func (m *metricBigipPoolPacketCount) init() {
	m.data.SetName("bigip.pool.packet.count")
	m.data.SetDescription("Number of packets transmitted to and from the pool.")
	m.data.SetUnit("{packets}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipPoolPacketCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipPoolPacketCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipPoolPacketCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipPoolPacketCount(cfg MetricConfig) metricBigipPoolPacketCount {
	m := metricBigipPoolPacketCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipPoolRequestCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.pool.request.count metric with initial data.
func (m *metricBigipPoolRequestCount) init() {
	m.data.SetName("bigip.pool.request.count")
	m.data.SetDescription("Number of requests to the pool.")
	m.data.SetUnit("{requests}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricBigipPoolRequestCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipPoolRequestCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipPoolRequestCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipPoolRequestCount(cfg MetricConfig) metricBigipPoolRequestCount {
	m := metricBigipPoolRequestCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipPoolMemberAvailability struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.pool_member.availability metric with initial data.
func (m *metricBigipPoolMemberAvailability) init() {
	m.data.SetName("bigip.pool_member.availability")
	m.data.SetDescription("Availability of the pool member.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipPoolMemberAvailability) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, availabilityStatusAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("status", availabilityStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipPoolMemberAvailability) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipPoolMemberAvailability) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipPoolMemberAvailability(cfg MetricConfig) metricBigipPoolMemberAvailability {
	m := metricBigipPoolMemberAvailability{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipPoolMemberConnectionCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.pool_member.connection.count metric with initial data.
func (m *metricBigipPoolMemberConnectionCount) init() {
	m.data.SetName("bigip.pool_member.connection.count")
	m.data.SetDescription("Current number of connections to the pool member.")
	m.data.SetUnit("{connections}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricBigipPoolMemberConnectionCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipPoolMemberConnectionCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipPoolMemberConnectionCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipPoolMemberConnectionCount(cfg MetricConfig) metricBigipPoolMemberConnectionCount {
	m := metricBigipPoolMemberConnectionCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipPoolMemberDataTransmitted struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.pool_member.data.transmitted metric with initial data.
func (m *metricBigipPoolMemberDataTransmitted) init() {
	m.data.SetName("bigip.pool_member.data.transmitted")
	m.data.SetDescription("Amount of data transmitted to and from the pool member.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipPoolMemberDataTransmitted) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipPoolMemberDataTransmitted) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipPoolMemberDataTransmitted) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipPoolMemberDataTransmitted(cfg MetricConfig) metricBigipPoolMemberDataTransmitted {
	m := metricBigipPoolMemberDataTransmitted{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipPoolMemberEnabled struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.pool_member.enabled metric with initial data.
func (m *metricBigipPoolMemberEnabled) init() {
	m.data.SetName("bigip.pool_member.enabled")
	m.data.SetDescription("Enabled state of of the pool member.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipPoolMemberEnabled) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, enabledStatusAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("status", enabledStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipPoolMemberEnabled) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipPoolMemberEnabled) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipPoolMemberEnabled(cfg MetricConfig) metricBigipPoolMemberEnabled {
	m := metricBigipPoolMemberEnabled{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipPoolMemberPacketCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.pool_member.packet.count metric with initial data.
func (m *metricBigipPoolMemberPacketCount) init() {
	m.data.SetName("bigip.pool_member.packet.count")
	m.data.SetDescription("Number of packets transmitted to and from the pool member.")
	m.data.SetUnit("{packets}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipPoolMemberPacketCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipPoolMemberPacketCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipPoolMemberPacketCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipPoolMemberPacketCount(cfg MetricConfig) metricBigipPoolMemberPacketCount {
	m := metricBigipPoolMemberPacketCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipPoolMemberRequestCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.pool_member.request.count metric with initial data.
func (m *metricBigipPoolMemberRequestCount) init() {
	m.data.SetName("bigip.pool_member.request.count")
	m.data.SetDescription("Number of requests to the pool member.")
	m.data.SetUnit("{requests}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricBigipPoolMemberRequestCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipPoolMemberRequestCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipPoolMemberRequestCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipPoolMemberRequestCount(cfg MetricConfig) metricBigipPoolMemberRequestCount {
	m := metricBigipPoolMemberRequestCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipPoolMemberSessionCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.pool_member.session.count metric with initial data.
func (m *metricBigipPoolMemberSessionCount) init() {
	m.data.SetName("bigip.pool_member.session.count")
	m.data.SetDescription("Current number of sessions for the pool member.")
	m.data.SetUnit("{sessions}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricBigipPoolMemberSessionCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipPoolMemberSessionCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipPoolMemberSessionCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipPoolMemberSessionCount(cfg MetricConfig) metricBigipPoolMemberSessionCount {
	m := metricBigipPoolMemberSessionCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipVirtualServerAvailability struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.virtual_server.availability metric with initial data.
func (m *metricBigipVirtualServerAvailability) init() {
	m.data.SetName("bigip.virtual_server.availability")
	m.data.SetDescription("Availability of the virtual server.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipVirtualServerAvailability) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, availabilityStatusAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("status", availabilityStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipVirtualServerAvailability) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipVirtualServerAvailability) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipVirtualServerAvailability(cfg MetricConfig) metricBigipVirtualServerAvailability {
	m := metricBigipVirtualServerAvailability{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipVirtualServerConnectionCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.virtual_server.connection.count metric with initial data.
func (m *metricBigipVirtualServerConnectionCount) init() {
	m.data.SetName("bigip.virtual_server.connection.count")
	m.data.SetDescription("Current number of connections to the virtual server.")
	m.data.SetUnit("{connections}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricBigipVirtualServerConnectionCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipVirtualServerConnectionCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipVirtualServerConnectionCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipVirtualServerConnectionCount(cfg MetricConfig) metricBigipVirtualServerConnectionCount {
	m := metricBigipVirtualServerConnectionCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipVirtualServerDataTransmitted struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.virtual_server.data.transmitted metric with initial data.
func (m *metricBigipVirtualServerDataTransmitted) init() {
	m.data.SetName("bigip.virtual_server.data.transmitted")
	m.data.SetDescription("Amount of data transmitted to and from the virtual server.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipVirtualServerDataTransmitted) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipVirtualServerDataTransmitted) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipVirtualServerDataTransmitted) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipVirtualServerDataTransmitted(cfg MetricConfig) metricBigipVirtualServerDataTransmitted {
	m := metricBigipVirtualServerDataTransmitted{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipVirtualServerEnabled struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.virtual_server.enabled metric with initial data.
func (m *metricBigipVirtualServerEnabled) init() {
	m.data.SetName("bigip.virtual_server.enabled")
	m.data.SetDescription("Enabled state of of the virtual server.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipVirtualServerEnabled) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, enabledStatusAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("status", enabledStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipVirtualServerEnabled) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipVirtualServerEnabled) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipVirtualServerEnabled(cfg MetricConfig) metricBigipVirtualServerEnabled {
	m := metricBigipVirtualServerEnabled{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipVirtualServerPacketCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.virtual_server.packet.count metric with initial data.
func (m *metricBigipVirtualServerPacketCount) init() {
	m.data.SetName("bigip.virtual_server.packet.count")
	m.data.SetDescription("Number of packets transmitted to and from the virtual server.")
	m.data.SetUnit("{packets}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricBigipVirtualServerPacketCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipVirtualServerPacketCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipVirtualServerPacketCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipVirtualServerPacketCount(cfg MetricConfig) metricBigipVirtualServerPacketCount {
	m := metricBigipVirtualServerPacketCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricBigipVirtualServerRequestCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills bigip.virtual_server.request.count metric with initial data.
func (m *metricBigipVirtualServerRequestCount) init() {
	m.data.SetName("bigip.virtual_server.request.count")
	m.data.SetDescription("Number of requests to the virtual server.")
	m.data.SetUnit("{requests}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricBigipVirtualServerRequestCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricBigipVirtualServerRequestCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricBigipVirtualServerRequestCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricBigipVirtualServerRequestCount(cfg MetricConfig) metricBigipVirtualServerRequestCount {
	m := metricBigipVirtualServerRequestCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// missedEmitsToDropRMB is number of missed emits after which resource builder will be dropped from MetricsBuilder.rmbMap.
// Potentially, this value can be made configurable through a MetricsBuilder option.
const missedEmitsToDropRMB = 5

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config    MetricsBuilderConfig                 // config of the metrics builder.
	buildInfo component.BuildInfo                  // contains version information
	startTime pcommon.Timestamp                    // start time that will be applied to all recorded data points.
	rmbMap    map[[16]byte]*ResourceMetricsBuilder // map of resource builders by resource hash.
}

type ResourceMetricsBuilder struct {
	buildInfo                               component.BuildInfo
	startTime                               pcommon.Timestamp // start time that will be applied to all recorded data points.
	metricsCapacity                         int               // maximum observed number of metrics per resource.
	resource                                pcommon.Resource
	missedEmits                             int
	metricBigipNodeAvailability             metricBigipNodeAvailability
	metricBigipNodeConnectionCount          metricBigipNodeConnectionCount
	metricBigipNodeDataTransmitted          metricBigipNodeDataTransmitted
	metricBigipNodeEnabled                  metricBigipNodeEnabled
	metricBigipNodePacketCount              metricBigipNodePacketCount
	metricBigipNodeRequestCount             metricBigipNodeRequestCount
	metricBigipNodeSessionCount             metricBigipNodeSessionCount
	metricBigipPoolAvailability             metricBigipPoolAvailability
	metricBigipPoolConnectionCount          metricBigipPoolConnectionCount
	metricBigipPoolDataTransmitted          metricBigipPoolDataTransmitted
	metricBigipPoolEnabled                  metricBigipPoolEnabled
	metricBigipPoolMemberCount              metricBigipPoolMemberCount
	metricBigipPoolPacketCount              metricBigipPoolPacketCount
	metricBigipPoolRequestCount             metricBigipPoolRequestCount
	metricBigipPoolMemberAvailability       metricBigipPoolMemberAvailability
	metricBigipPoolMemberConnectionCount    metricBigipPoolMemberConnectionCount
	metricBigipPoolMemberDataTransmitted    metricBigipPoolMemberDataTransmitted
	metricBigipPoolMemberEnabled            metricBigipPoolMemberEnabled
	metricBigipPoolMemberPacketCount        metricBigipPoolMemberPacketCount
	metricBigipPoolMemberRequestCount       metricBigipPoolMemberRequestCount
	metricBigipPoolMemberSessionCount       metricBigipPoolMemberSessionCount
	metricBigipVirtualServerAvailability    metricBigipVirtualServerAvailability
	metricBigipVirtualServerConnectionCount metricBigipVirtualServerConnectionCount
	metricBigipVirtualServerDataTransmitted metricBigipVirtualServerDataTransmitted
	metricBigipVirtualServerEnabled         metricBigipVirtualServerEnabled
	metricBigipVirtualServerPacketCount     metricBigipVirtualServerPacketCount
	metricBigipVirtualServerRequestCount    metricBigipVirtualServerRequestCount
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.CreateSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:    mbc,
		startTime: pcommon.NewTimestampFromTime(time.Now()),
		buildInfo: settings.BuildInfo,
		rmbMap:    make(map[[16]byte]*ResourceMetricsBuilder),
	}
	for _, opt := range options {
		opt(mb)
	}
	return mb
}

// resourceMetricsBuilderOption applies changes to provided resource metrics.
type resourceMetricsBuilderOption func(*ResourceMetricsBuilder)

// WithStartTimeOverride sets start time for all the resource metrics data points.
func WithStartTimeOverride(start pcommon.Timestamp) resourceMetricsBuilderOption {
	return func(rmb *ResourceMetricsBuilder) {
		rmb.startTime = start
	}
}

// ResourceMetricsBuilder returns a ResourceMetricsBuilder that can be used to record metrics for a specific resource.
// It requires Resource to be provided which should be built with ResourceBuilder.
func (mb *MetricsBuilder) ResourceMetricsBuilder(res pcommon.Resource, options ...resourceMetricsBuilderOption) *ResourceMetricsBuilder {
	hash := pdatautil.MapHash(res.Attributes())
	if rmb, ok := mb.rmbMap[hash]; ok {
		return rmb
	}
	rmb := &ResourceMetricsBuilder{
		startTime:                               mb.startTime,
		buildInfo:                               mb.buildInfo,
		resource:                                res,
		metricBigipNodeAvailability:             newMetricBigipNodeAvailability(mb.config.Metrics.BigipNodeAvailability),
		metricBigipNodeConnectionCount:          newMetricBigipNodeConnectionCount(mb.config.Metrics.BigipNodeConnectionCount),
		metricBigipNodeDataTransmitted:          newMetricBigipNodeDataTransmitted(mb.config.Metrics.BigipNodeDataTransmitted),
		metricBigipNodeEnabled:                  newMetricBigipNodeEnabled(mb.config.Metrics.BigipNodeEnabled),
		metricBigipNodePacketCount:              newMetricBigipNodePacketCount(mb.config.Metrics.BigipNodePacketCount),
		metricBigipNodeRequestCount:             newMetricBigipNodeRequestCount(mb.config.Metrics.BigipNodeRequestCount),
		metricBigipNodeSessionCount:             newMetricBigipNodeSessionCount(mb.config.Metrics.BigipNodeSessionCount),
		metricBigipPoolAvailability:             newMetricBigipPoolAvailability(mb.config.Metrics.BigipPoolAvailability),
		metricBigipPoolConnectionCount:          newMetricBigipPoolConnectionCount(mb.config.Metrics.BigipPoolConnectionCount),
		metricBigipPoolDataTransmitted:          newMetricBigipPoolDataTransmitted(mb.config.Metrics.BigipPoolDataTransmitted),
		metricBigipPoolEnabled:                  newMetricBigipPoolEnabled(mb.config.Metrics.BigipPoolEnabled),
		metricBigipPoolMemberCount:              newMetricBigipPoolMemberCount(mb.config.Metrics.BigipPoolMemberCount),
		metricBigipPoolPacketCount:              newMetricBigipPoolPacketCount(mb.config.Metrics.BigipPoolPacketCount),
		metricBigipPoolRequestCount:             newMetricBigipPoolRequestCount(mb.config.Metrics.BigipPoolRequestCount),
		metricBigipPoolMemberAvailability:       newMetricBigipPoolMemberAvailability(mb.config.Metrics.BigipPoolMemberAvailability),
		metricBigipPoolMemberConnectionCount:    newMetricBigipPoolMemberConnectionCount(mb.config.Metrics.BigipPoolMemberConnectionCount),
		metricBigipPoolMemberDataTransmitted:    newMetricBigipPoolMemberDataTransmitted(mb.config.Metrics.BigipPoolMemberDataTransmitted),
		metricBigipPoolMemberEnabled:            newMetricBigipPoolMemberEnabled(mb.config.Metrics.BigipPoolMemberEnabled),
		metricBigipPoolMemberPacketCount:        newMetricBigipPoolMemberPacketCount(mb.config.Metrics.BigipPoolMemberPacketCount),
		metricBigipPoolMemberRequestCount:       newMetricBigipPoolMemberRequestCount(mb.config.Metrics.BigipPoolMemberRequestCount),
		metricBigipPoolMemberSessionCount:       newMetricBigipPoolMemberSessionCount(mb.config.Metrics.BigipPoolMemberSessionCount),
		metricBigipVirtualServerAvailability:    newMetricBigipVirtualServerAvailability(mb.config.Metrics.BigipVirtualServerAvailability),
		metricBigipVirtualServerConnectionCount: newMetricBigipVirtualServerConnectionCount(mb.config.Metrics.BigipVirtualServerConnectionCount),
		metricBigipVirtualServerDataTransmitted: newMetricBigipVirtualServerDataTransmitted(mb.config.Metrics.BigipVirtualServerDataTransmitted),
		metricBigipVirtualServerEnabled:         newMetricBigipVirtualServerEnabled(mb.config.Metrics.BigipVirtualServerEnabled),
		metricBigipVirtualServerPacketCount:     newMetricBigipVirtualServerPacketCount(mb.config.Metrics.BigipVirtualServerPacketCount),
		metricBigipVirtualServerRequestCount:    newMetricBigipVirtualServerRequestCount(mb.config.Metrics.BigipVirtualServerRequestCount),
	}
	for _, op := range options {
		op(rmb)
	}
	mb.rmbMap[hash] = rmb
	return rmb
}

// NewResourceBuilder returns a new resource builder that should be used to build a resource associated with for the emitted metrics.
func (mb *MetricsBuilder) NewResourceBuilder() *ResourceBuilder {
	return NewResourceBuilder(mb.config.ResourceAttributes)
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (rmb *ResourceMetricsBuilder) updateCapacity(ms pmetric.MetricSlice) {
	if rmb.metricsCapacity < ms.Len() {
		rmb.metricsCapacity = ms.Len()
	}
}

// emit emits all the metrics accumulated by the ResourceMetricsBuilder and updates the internal state to be ready for
// recording another set of metrics. It returns true if any metrics were emitted.
func (rmb *ResourceMetricsBuilder) emit(m pmetric.Metrics) bool {
	sm := pmetric.NewScopeMetrics()
	sm.Metrics().EnsureCapacity(rmb.metricsCapacity)
	rmb.metricBigipNodeAvailability.emit(sm.Metrics())
	rmb.metricBigipNodeConnectionCount.emit(sm.Metrics())
	rmb.metricBigipNodeDataTransmitted.emit(sm.Metrics())
	rmb.metricBigipNodeEnabled.emit(sm.Metrics())
	rmb.metricBigipNodePacketCount.emit(sm.Metrics())
	rmb.metricBigipNodeRequestCount.emit(sm.Metrics())
	rmb.metricBigipNodeSessionCount.emit(sm.Metrics())
	rmb.metricBigipPoolAvailability.emit(sm.Metrics())
	rmb.metricBigipPoolConnectionCount.emit(sm.Metrics())
	rmb.metricBigipPoolDataTransmitted.emit(sm.Metrics())
	rmb.metricBigipPoolEnabled.emit(sm.Metrics())
	rmb.metricBigipPoolMemberCount.emit(sm.Metrics())
	rmb.metricBigipPoolPacketCount.emit(sm.Metrics())
	rmb.metricBigipPoolRequestCount.emit(sm.Metrics())
	rmb.metricBigipPoolMemberAvailability.emit(sm.Metrics())
	rmb.metricBigipPoolMemberConnectionCount.emit(sm.Metrics())
	rmb.metricBigipPoolMemberDataTransmitted.emit(sm.Metrics())
	rmb.metricBigipPoolMemberEnabled.emit(sm.Metrics())
	rmb.metricBigipPoolMemberPacketCount.emit(sm.Metrics())
	rmb.metricBigipPoolMemberRequestCount.emit(sm.Metrics())
	rmb.metricBigipPoolMemberSessionCount.emit(sm.Metrics())
	rmb.metricBigipVirtualServerAvailability.emit(sm.Metrics())
	rmb.metricBigipVirtualServerConnectionCount.emit(sm.Metrics())
	rmb.metricBigipVirtualServerDataTransmitted.emit(sm.Metrics())
	rmb.metricBigipVirtualServerEnabled.emit(sm.Metrics())
	rmb.metricBigipVirtualServerPacketCount.emit(sm.Metrics())
	rmb.metricBigipVirtualServerRequestCount.emit(sm.Metrics())
	if sm.Metrics().Len() == 0 {
		return false
	}
	rmb.updateCapacity(sm.Metrics())
	sm.Scope().SetName("otelcol/bigipreceiver")
	sm.Scope().SetVersion(rmb.buildInfo.Version)
	rm := m.ResourceMetrics().AppendEmpty()
	rmb.resource.CopyTo(rm.Resource())
	sm.MoveTo(rm.ScopeMetrics().AppendEmpty())
	return true
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit() pmetric.Metrics {
	m := pmetric.NewMetrics()
	for _, rmb := range mb.rmbMap {
		if ok := rmb.emit(m); !ok {
			rmb.missedEmits++
		}
	}
	for k, rmb := range mb.rmbMap {
		if rmb.missedEmits >= missedEmitsToDropRMB {
			delete(mb.rmbMap, k)
		}
	}
	return m
}

// RecordBigipNodeAvailabilityDataPoint adds a data point to bigip.node.availability metric.
func (rmb *ResourceMetricsBuilder) RecordBigipNodeAvailabilityDataPoint(ts pcommon.Timestamp, val int64, availabilityStatusAttributeValue AttributeAvailabilityStatus) {
	rmb.metricBigipNodeAvailability.recordDataPoint(rmb.startTime, ts, val, availabilityStatusAttributeValue.String())
}

// RecordBigipNodeConnectionCountDataPoint adds a data point to bigip.node.connection.count metric.
func (rmb *ResourceMetricsBuilder) RecordBigipNodeConnectionCountDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricBigipNodeConnectionCount.recordDataPoint(rmb.startTime, ts, val)
}

// RecordBigipNodeDataTransmittedDataPoint adds a data point to bigip.node.data.transmitted metric.
func (rmb *ResourceMetricsBuilder) RecordBigipNodeDataTransmittedDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	rmb.metricBigipNodeDataTransmitted.recordDataPoint(rmb.startTime, ts, val, directionAttributeValue.String())
}

// RecordBigipNodeEnabledDataPoint adds a data point to bigip.node.enabled metric.
func (rmb *ResourceMetricsBuilder) RecordBigipNodeEnabledDataPoint(ts pcommon.Timestamp, val int64, enabledStatusAttributeValue AttributeEnabledStatus) {
	rmb.metricBigipNodeEnabled.recordDataPoint(rmb.startTime, ts, val, enabledStatusAttributeValue.String())
}

// RecordBigipNodePacketCountDataPoint adds a data point to bigip.node.packet.count metric.
func (rmb *ResourceMetricsBuilder) RecordBigipNodePacketCountDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	rmb.metricBigipNodePacketCount.recordDataPoint(rmb.startTime, ts, val, directionAttributeValue.String())
}

// RecordBigipNodeRequestCountDataPoint adds a data point to bigip.node.request.count metric.
func (rmb *ResourceMetricsBuilder) RecordBigipNodeRequestCountDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricBigipNodeRequestCount.recordDataPoint(rmb.startTime, ts, val)
}

// RecordBigipNodeSessionCountDataPoint adds a data point to bigip.node.session.count metric.
func (rmb *ResourceMetricsBuilder) RecordBigipNodeSessionCountDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricBigipNodeSessionCount.recordDataPoint(rmb.startTime, ts, val)
}

// RecordBigipPoolAvailabilityDataPoint adds a data point to bigip.pool.availability metric.
func (rmb *ResourceMetricsBuilder) RecordBigipPoolAvailabilityDataPoint(ts pcommon.Timestamp, val int64, availabilityStatusAttributeValue AttributeAvailabilityStatus) {
	rmb.metricBigipPoolAvailability.recordDataPoint(rmb.startTime, ts, val, availabilityStatusAttributeValue.String())
}

// RecordBigipPoolConnectionCountDataPoint adds a data point to bigip.pool.connection.count metric.
func (rmb *ResourceMetricsBuilder) RecordBigipPoolConnectionCountDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricBigipPoolConnectionCount.recordDataPoint(rmb.startTime, ts, val)
}

// RecordBigipPoolDataTransmittedDataPoint adds a data point to bigip.pool.data.transmitted metric.
func (rmb *ResourceMetricsBuilder) RecordBigipPoolDataTransmittedDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	rmb.metricBigipPoolDataTransmitted.recordDataPoint(rmb.startTime, ts, val, directionAttributeValue.String())
}

// RecordBigipPoolEnabledDataPoint adds a data point to bigip.pool.enabled metric.
func (rmb *ResourceMetricsBuilder) RecordBigipPoolEnabledDataPoint(ts pcommon.Timestamp, val int64, enabledStatusAttributeValue AttributeEnabledStatus) {
	rmb.metricBigipPoolEnabled.recordDataPoint(rmb.startTime, ts, val, enabledStatusAttributeValue.String())
}

// RecordBigipPoolMemberCountDataPoint adds a data point to bigip.pool.member.count metric.
func (rmb *ResourceMetricsBuilder) RecordBigipPoolMemberCountDataPoint(ts pcommon.Timestamp, val int64, activeStatusAttributeValue AttributeActiveStatus) {
	rmb.metricBigipPoolMemberCount.recordDataPoint(rmb.startTime, ts, val, activeStatusAttributeValue.String())
}

// RecordBigipPoolPacketCountDataPoint adds a data point to bigip.pool.packet.count metric.
func (rmb *ResourceMetricsBuilder) RecordBigipPoolPacketCountDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	rmb.metricBigipPoolPacketCount.recordDataPoint(rmb.startTime, ts, val, directionAttributeValue.String())
}

// RecordBigipPoolRequestCountDataPoint adds a data point to bigip.pool.request.count metric.
func (rmb *ResourceMetricsBuilder) RecordBigipPoolRequestCountDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricBigipPoolRequestCount.recordDataPoint(rmb.startTime, ts, val)
}

// RecordBigipPoolMemberAvailabilityDataPoint adds a data point to bigip.pool_member.availability metric.
func (rmb *ResourceMetricsBuilder) RecordBigipPoolMemberAvailabilityDataPoint(ts pcommon.Timestamp, val int64, availabilityStatusAttributeValue AttributeAvailabilityStatus) {
	rmb.metricBigipPoolMemberAvailability.recordDataPoint(rmb.startTime, ts, val, availabilityStatusAttributeValue.String())
}

// RecordBigipPoolMemberConnectionCountDataPoint adds a data point to bigip.pool_member.connection.count metric.
func (rmb *ResourceMetricsBuilder) RecordBigipPoolMemberConnectionCountDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricBigipPoolMemberConnectionCount.recordDataPoint(rmb.startTime, ts, val)
}

// RecordBigipPoolMemberDataTransmittedDataPoint adds a data point to bigip.pool_member.data.transmitted metric.
func (rmb *ResourceMetricsBuilder) RecordBigipPoolMemberDataTransmittedDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	rmb.metricBigipPoolMemberDataTransmitted.recordDataPoint(rmb.startTime, ts, val, directionAttributeValue.String())
}

// RecordBigipPoolMemberEnabledDataPoint adds a data point to bigip.pool_member.enabled metric.
func (rmb *ResourceMetricsBuilder) RecordBigipPoolMemberEnabledDataPoint(ts pcommon.Timestamp, val int64, enabledStatusAttributeValue AttributeEnabledStatus) {
	rmb.metricBigipPoolMemberEnabled.recordDataPoint(rmb.startTime, ts, val, enabledStatusAttributeValue.String())
}

// RecordBigipPoolMemberPacketCountDataPoint adds a data point to bigip.pool_member.packet.count metric.
func (rmb *ResourceMetricsBuilder) RecordBigipPoolMemberPacketCountDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	rmb.metricBigipPoolMemberPacketCount.recordDataPoint(rmb.startTime, ts, val, directionAttributeValue.String())
}

// RecordBigipPoolMemberRequestCountDataPoint adds a data point to bigip.pool_member.request.count metric.
func (rmb *ResourceMetricsBuilder) RecordBigipPoolMemberRequestCountDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricBigipPoolMemberRequestCount.recordDataPoint(rmb.startTime, ts, val)
}

// RecordBigipPoolMemberSessionCountDataPoint adds a data point to bigip.pool_member.session.count metric.
func (rmb *ResourceMetricsBuilder) RecordBigipPoolMemberSessionCountDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricBigipPoolMemberSessionCount.recordDataPoint(rmb.startTime, ts, val)
}

// RecordBigipVirtualServerAvailabilityDataPoint adds a data point to bigip.virtual_server.availability metric.
func (rmb *ResourceMetricsBuilder) RecordBigipVirtualServerAvailabilityDataPoint(ts pcommon.Timestamp, val int64, availabilityStatusAttributeValue AttributeAvailabilityStatus) {
	rmb.metricBigipVirtualServerAvailability.recordDataPoint(rmb.startTime, ts, val, availabilityStatusAttributeValue.String())
}

// RecordBigipVirtualServerConnectionCountDataPoint adds a data point to bigip.virtual_server.connection.count metric.
func (rmb *ResourceMetricsBuilder) RecordBigipVirtualServerConnectionCountDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricBigipVirtualServerConnectionCount.recordDataPoint(rmb.startTime, ts, val)
}

// RecordBigipVirtualServerDataTransmittedDataPoint adds a data point to bigip.virtual_server.data.transmitted metric.
func (rmb *ResourceMetricsBuilder) RecordBigipVirtualServerDataTransmittedDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	rmb.metricBigipVirtualServerDataTransmitted.recordDataPoint(rmb.startTime, ts, val, directionAttributeValue.String())
}

// RecordBigipVirtualServerEnabledDataPoint adds a data point to bigip.virtual_server.enabled metric.
func (rmb *ResourceMetricsBuilder) RecordBigipVirtualServerEnabledDataPoint(ts pcommon.Timestamp, val int64, enabledStatusAttributeValue AttributeEnabledStatus) {
	rmb.metricBigipVirtualServerEnabled.recordDataPoint(rmb.startTime, ts, val, enabledStatusAttributeValue.String())
}

// RecordBigipVirtualServerPacketCountDataPoint adds a data point to bigip.virtual_server.packet.count metric.
func (rmb *ResourceMetricsBuilder) RecordBigipVirtualServerPacketCountDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	rmb.metricBigipVirtualServerPacketCount.recordDataPoint(rmb.startTime, ts, val, directionAttributeValue.String())
}

// RecordBigipVirtualServerRequestCountDataPoint adds a data point to bigip.virtual_server.request.count metric.
func (rmb *ResourceMetricsBuilder) RecordBigipVirtualServerRequestCountDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricBigipVirtualServerRequestCount.recordDataPoint(rmb.startTime, ts, val)
}

// Reset resets the ResourceMetricsBuilder to its initial state. It should be used when external metrics source is
// restarted, and the ResourceMetricsBuilder should update its startTime and reset it's internal state accordingly.
func (rmb *ResourceMetricsBuilder) Reset(options ...resourceMetricsBuilderOption) {
	rmb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(rmb)
	}
}
