// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"

	"github.com/open-telemetry/opentelemetry-collector-contrib/pkg/pdatautil"
)

// AttributeDirection specifies the a value direction attribute.
type AttributeDirection int

const (
	_ AttributeDirection = iota
	AttributeDirectionIn
	AttributeDirectionOut
)

// String returns the string representation of the AttributeDirection.
func (av AttributeDirection) String() string {
	switch av {
	case AttributeDirectionIn:
		return "in"
	case AttributeDirectionOut:
		return "out"
	}
	return ""
}

// MapAttributeDirection is a helper map of string to AttributeDirection attribute value.
var MapAttributeDirection = map[string]AttributeDirection{
	"in":  AttributeDirectionIn,
	"out": AttributeDirectionOut,
}

// AttributeExecutorTaskResult specifies the a value executor_task_result attribute.
type AttributeExecutorTaskResult int

const (
	_ AttributeExecutorTaskResult = iota
	AttributeExecutorTaskResultCompleted
	AttributeExecutorTaskResultFailed
)

// String returns the string representation of the AttributeExecutorTaskResult.
func (av AttributeExecutorTaskResult) String() string {
	switch av {
	case AttributeExecutorTaskResultCompleted:
		return "completed"
	case AttributeExecutorTaskResultFailed:
		return "failed"
	}
	return ""
}

// MapAttributeExecutorTaskResult is a helper map of string to AttributeExecutorTaskResult attribute value.
var MapAttributeExecutorTaskResult = map[string]AttributeExecutorTaskResult{
	"completed": AttributeExecutorTaskResultCompleted,
	"failed":    AttributeExecutorTaskResultFailed,
}

// AttributeGcType specifies the a value gc_type attribute.
type AttributeGcType int

const (
	_ AttributeGcType = iota
	AttributeGcTypeMajor
	AttributeGcTypeMinor
)

// String returns the string representation of the AttributeGcType.
func (av AttributeGcType) String() string {
	switch av {
	case AttributeGcTypeMajor:
		return "major"
	case AttributeGcTypeMinor:
		return "minor"
	}
	return ""
}

// MapAttributeGcType is a helper map of string to AttributeGcType attribute value.
var MapAttributeGcType = map[string]AttributeGcType{
	"major": AttributeGcTypeMajor,
	"minor": AttributeGcTypeMinor,
}

// AttributeJobResult specifies the a value job_result attribute.
type AttributeJobResult int

const (
	_ AttributeJobResult = iota
	AttributeJobResultCompleted
	AttributeJobResultFailed
	AttributeJobResultSkipped
)

// String returns the string representation of the AttributeJobResult.
func (av AttributeJobResult) String() string {
	switch av {
	case AttributeJobResultCompleted:
		return "completed"
	case AttributeJobResultFailed:
		return "failed"
	case AttributeJobResultSkipped:
		return "skipped"
	}
	return ""
}

// MapAttributeJobResult is a helper map of string to AttributeJobResult attribute value.
var MapAttributeJobResult = map[string]AttributeJobResult{
	"completed": AttributeJobResultCompleted,
	"failed":    AttributeJobResultFailed,
	"skipped":   AttributeJobResultSkipped,
}

// AttributeLocation specifies the a value location attribute.
type AttributeLocation int

const (
	_ AttributeLocation = iota
	AttributeLocationOnHeap
	AttributeLocationOffHeap
)

// String returns the string representation of the AttributeLocation.
func (av AttributeLocation) String() string {
	switch av {
	case AttributeLocationOnHeap:
		return "on_heap"
	case AttributeLocationOffHeap:
		return "off_heap"
	}
	return ""
}

// MapAttributeLocation is a helper map of string to AttributeLocation attribute value.
var MapAttributeLocation = map[string]AttributeLocation{
	"on_heap":  AttributeLocationOnHeap,
	"off_heap": AttributeLocationOffHeap,
}

// AttributePoolMemoryType specifies the a value pool_memory_type attribute.
type AttributePoolMemoryType int

const (
	_ AttributePoolMemoryType = iota
	AttributePoolMemoryTypeDirect
	AttributePoolMemoryTypeMapped
)

// String returns the string representation of the AttributePoolMemoryType.
func (av AttributePoolMemoryType) String() string {
	switch av {
	case AttributePoolMemoryTypeDirect:
		return "direct"
	case AttributePoolMemoryTypeMapped:
		return "mapped"
	}
	return ""
}

// MapAttributePoolMemoryType is a helper map of string to AttributePoolMemoryType attribute value.
var MapAttributePoolMemoryType = map[string]AttributePoolMemoryType{
	"direct": AttributePoolMemoryTypeDirect,
	"mapped": AttributePoolMemoryTypeMapped,
}

// AttributeSchedulerStatus specifies the a value scheduler_status attribute.
type AttributeSchedulerStatus int

const (
	_ AttributeSchedulerStatus = iota
	AttributeSchedulerStatusWaiting
	AttributeSchedulerStatusRunning
)

// String returns the string representation of the AttributeSchedulerStatus.
func (av AttributeSchedulerStatus) String() string {
	switch av {
	case AttributeSchedulerStatusWaiting:
		return "waiting"
	case AttributeSchedulerStatusRunning:
		return "running"
	}
	return ""
}

// MapAttributeSchedulerStatus is a helper map of string to AttributeSchedulerStatus attribute value.
var MapAttributeSchedulerStatus = map[string]AttributeSchedulerStatus{
	"waiting": AttributeSchedulerStatusWaiting,
	"running": AttributeSchedulerStatusRunning,
}

// AttributeSource specifies the a value source attribute.
type AttributeSource int

const (
	_ AttributeSource = iota
	AttributeSourceLocal
	AttributeSourceRemote
)

// String returns the string representation of the AttributeSource.
func (av AttributeSource) String() string {
	switch av {
	case AttributeSourceLocal:
		return "local"
	case AttributeSourceRemote:
		return "remote"
	}
	return ""
}

// MapAttributeSource is a helper map of string to AttributeSource attribute value.
var MapAttributeSource = map[string]AttributeSource{
	"local":  AttributeSourceLocal,
	"remote": AttributeSourceRemote,
}

// AttributeStageTaskResult specifies the a value stage_task_result attribute.
type AttributeStageTaskResult int

const (
	_ AttributeStageTaskResult = iota
	AttributeStageTaskResultCompleted
	AttributeStageTaskResultFailed
	AttributeStageTaskResultKilled
)

// String returns the string representation of the AttributeStageTaskResult.
func (av AttributeStageTaskResult) String() string {
	switch av {
	case AttributeStageTaskResultCompleted:
		return "completed"
	case AttributeStageTaskResultFailed:
		return "failed"
	case AttributeStageTaskResultKilled:
		return "killed"
	}
	return ""
}

// MapAttributeStageTaskResult is a helper map of string to AttributeStageTaskResult attribute value.
var MapAttributeStageTaskResult = map[string]AttributeStageTaskResult{
	"completed": AttributeStageTaskResultCompleted,
	"failed":    AttributeStageTaskResultFailed,
	"killed":    AttributeStageTaskResultKilled,
}

// AttributeState specifies the a value state attribute.
type AttributeState int

const (
	_ AttributeState = iota
	AttributeStateUsed
	AttributeStateFree
)

// String returns the string representation of the AttributeState.
func (av AttributeState) String() string {
	switch av {
	case AttributeStateUsed:
		return "used"
	case AttributeStateFree:
		return "free"
	}
	return ""
}

// MapAttributeState is a helper map of string to AttributeState attribute value.
var MapAttributeState = map[string]AttributeState{
	"used": AttributeStateUsed,
	"free": AttributeStateFree,
}

type metricSparkDriverBlockManagerDiskUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.block_manager.disk.usage metric with initial data.
func (m *metricSparkDriverBlockManagerDiskUsage) init() {
	m.data.SetName("spark.driver.block_manager.disk.usage")
	m.data.SetDescription("Disk space used by the BlockManager.")
	m.data.SetUnit("mb")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverBlockManagerDiskUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverBlockManagerDiskUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverBlockManagerDiskUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverBlockManagerDiskUsage(cfg MetricConfig) metricSparkDriverBlockManagerDiskUsage {
	m := metricSparkDriverBlockManagerDiskUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverBlockManagerMemoryUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.block_manager.memory.usage metric with initial data.
func (m *metricSparkDriverBlockManagerMemoryUsage) init() {
	m.data.SetName("spark.driver.block_manager.memory.usage")
	m.data.SetDescription("Memory usage for the driver's BlockManager.")
	m.data.SetUnit("mb")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDriverBlockManagerMemoryUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string, stateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
	dp.Attributes().PutStr("state", stateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverBlockManagerMemoryUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverBlockManagerMemoryUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverBlockManagerMemoryUsage(cfg MetricConfig) metricSparkDriverBlockManagerMemoryUsage {
	m := metricSparkDriverBlockManagerMemoryUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverCodeGeneratorCompilationAverageTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.code_generator.compilation.average_time metric with initial data.
func (m *metricSparkDriverCodeGeneratorCompilationAverageTime) init() {
	m.data.SetName("spark.driver.code_generator.compilation.average_time")
	m.data.SetDescription("Average time spent during CodeGenerator source code compilation operations.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
}

func (m *metricSparkDriverCodeGeneratorCompilationAverageTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverCodeGeneratorCompilationAverageTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverCodeGeneratorCompilationAverageTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverCodeGeneratorCompilationAverageTime(cfg MetricConfig) metricSparkDriverCodeGeneratorCompilationAverageTime {
	m := metricSparkDriverCodeGeneratorCompilationAverageTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverCodeGeneratorCompilationCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.code_generator.compilation.count metric with initial data.
func (m *metricSparkDriverCodeGeneratorCompilationCount) init() {
	m.data.SetName("spark.driver.code_generator.compilation.count")
	m.data.SetDescription("Number of source code compilation operations performed by the CodeGenerator.")
	m.data.SetUnit("{ compilation }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverCodeGeneratorCompilationCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverCodeGeneratorCompilationCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverCodeGeneratorCompilationCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverCodeGeneratorCompilationCount(cfg MetricConfig) metricSparkDriverCodeGeneratorCompilationCount {
	m := metricSparkDriverCodeGeneratorCompilationCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverCodeGeneratorGeneratedClassAverageSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.code_generator.generated_class.average_size metric with initial data.
func (m *metricSparkDriverCodeGeneratorGeneratedClassAverageSize) init() {
	m.data.SetName("spark.driver.code_generator.generated_class.average_size")
	m.data.SetDescription("Average class size of the classes generated by the CodeGenerator.")
	m.data.SetUnit("bytes")
	m.data.SetEmptyGauge()
}

func (m *metricSparkDriverCodeGeneratorGeneratedClassAverageSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverCodeGeneratorGeneratedClassAverageSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverCodeGeneratorGeneratedClassAverageSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverCodeGeneratorGeneratedClassAverageSize(cfg MetricConfig) metricSparkDriverCodeGeneratorGeneratedClassAverageSize {
	m := metricSparkDriverCodeGeneratorGeneratedClassAverageSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverCodeGeneratorGeneratedClassCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.code_generator.generated_class.count metric with initial data.
func (m *metricSparkDriverCodeGeneratorGeneratedClassCount) init() {
	m.data.SetName("spark.driver.code_generator.generated_class.count")
	m.data.SetDescription("Number of classes generated by the CodeGenerator.")
	m.data.SetUnit("{ class }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverCodeGeneratorGeneratedClassCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverCodeGeneratorGeneratedClassCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverCodeGeneratorGeneratedClassCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverCodeGeneratorGeneratedClassCount(cfg MetricConfig) metricSparkDriverCodeGeneratorGeneratedClassCount {
	m := metricSparkDriverCodeGeneratorGeneratedClassCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverCodeGeneratorGeneratedMethodAverageSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.code_generator.generated_method.average_size metric with initial data.
func (m *metricSparkDriverCodeGeneratorGeneratedMethodAverageSize) init() {
	m.data.SetName("spark.driver.code_generator.generated_method.average_size")
	m.data.SetDescription("Average method size of the classes generated by the CodeGenerator.")
	m.data.SetUnit("bytes")
	m.data.SetEmptyGauge()
}

func (m *metricSparkDriverCodeGeneratorGeneratedMethodAverageSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverCodeGeneratorGeneratedMethodAverageSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverCodeGeneratorGeneratedMethodAverageSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverCodeGeneratorGeneratedMethodAverageSize(cfg MetricConfig) metricSparkDriverCodeGeneratorGeneratedMethodAverageSize {
	m := metricSparkDriverCodeGeneratorGeneratedMethodAverageSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverCodeGeneratorGeneratedMethodCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.code_generator.generated_method.count metric with initial data.
func (m *metricSparkDriverCodeGeneratorGeneratedMethodCount) init() {
	m.data.SetName("spark.driver.code_generator.generated_method.count")
	m.data.SetDescription("Number of methods generated by the CodeGenerator.")
	m.data.SetUnit("{ method }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverCodeGeneratorGeneratedMethodCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverCodeGeneratorGeneratedMethodCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverCodeGeneratorGeneratedMethodCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverCodeGeneratorGeneratedMethodCount(cfg MetricConfig) metricSparkDriverCodeGeneratorGeneratedMethodCount {
	m := metricSparkDriverCodeGeneratorGeneratedMethodCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverCodeGeneratorSourceCodeAverageSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.code_generator.source_code.average_size metric with initial data.
func (m *metricSparkDriverCodeGeneratorSourceCodeAverageSize) init() {
	m.data.SetName("spark.driver.code_generator.source_code.average_size")
	m.data.SetDescription("Average size of the source code generated by a CodeGenerator code generation operation.")
	m.data.SetUnit("bytes")
	m.data.SetEmptyGauge()
}

func (m *metricSparkDriverCodeGeneratorSourceCodeAverageSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverCodeGeneratorSourceCodeAverageSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverCodeGeneratorSourceCodeAverageSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverCodeGeneratorSourceCodeAverageSize(cfg MetricConfig) metricSparkDriverCodeGeneratorSourceCodeAverageSize {
	m := metricSparkDriverCodeGeneratorSourceCodeAverageSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverCodeGeneratorSourceCodeOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.code_generator.source_code.operations metric with initial data.
func (m *metricSparkDriverCodeGeneratorSourceCodeOperations) init() {
	m.data.SetName("spark.driver.code_generator.source_code.operations")
	m.data.SetDescription("Number of source code generation operations performed by the CodeGenerator.")
	m.data.SetUnit("{ operation }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverCodeGeneratorSourceCodeOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverCodeGeneratorSourceCodeOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverCodeGeneratorSourceCodeOperations) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverCodeGeneratorSourceCodeOperations(cfg MetricConfig) metricSparkDriverCodeGeneratorSourceCodeOperations {
	m := metricSparkDriverCodeGeneratorSourceCodeOperations{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverDagSchedulerJobActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.dag_scheduler.job.active metric with initial data.
func (m *metricSparkDriverDagSchedulerJobActive) init() {
	m.data.SetName("spark.driver.dag_scheduler.job.active")
	m.data.SetDescription("Number of active jobs currently being processed by the DAGScheduler.")
	m.data.SetUnit("{ job }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverDagSchedulerJobActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverDagSchedulerJobActive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverDagSchedulerJobActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverDagSchedulerJobActive(cfg MetricConfig) metricSparkDriverDagSchedulerJobActive {
	m := metricSparkDriverDagSchedulerJobActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverDagSchedulerJobCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.dag_scheduler.job.count metric with initial data.
func (m *metricSparkDriverDagSchedulerJobCount) init() {
	m.data.SetName("spark.driver.dag_scheduler.job.count")
	m.data.SetDescription("Number of jobs that have been submitted to the DAGScheduler.")
	m.data.SetUnit("{ job }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverDagSchedulerJobCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverDagSchedulerJobCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverDagSchedulerJobCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverDagSchedulerJobCount(cfg MetricConfig) metricSparkDriverDagSchedulerJobCount {
	m := metricSparkDriverDagSchedulerJobCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverDagSchedulerStageCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.dag_scheduler.stage.count metric with initial data.
func (m *metricSparkDriverDagSchedulerStageCount) init() {
	m.data.SetName("spark.driver.dag_scheduler.stage.count")
	m.data.SetDescription("Number of stages the DAGScheduler is either running or needs to run.")
	m.data.SetUnit("{ stage }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDriverDagSchedulerStageCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, schedulerStatusAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("status", schedulerStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverDagSchedulerStageCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverDagSchedulerStageCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverDagSchedulerStageCount(cfg MetricConfig) metricSparkDriverDagSchedulerStageCount {
	m := metricSparkDriverDagSchedulerStageCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverDagSchedulerStageFailed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.dag_scheduler.stage.failed metric with initial data.
func (m *metricSparkDriverDagSchedulerStageFailed) init() {
	m.data.SetName("spark.driver.dag_scheduler.stage.failed")
	m.data.SetDescription("Number of failed stages run by the DAGScheduler.")
	m.data.SetUnit("{ stage }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverDagSchedulerStageFailed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverDagSchedulerStageFailed) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverDagSchedulerStageFailed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverDagSchedulerStageFailed(cfg MetricConfig) metricSparkDriverDagSchedulerStageFailed {
	m := metricSparkDriverDagSchedulerStageFailed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverExecutorGcOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.executor.gc.operations metric with initial data.
func (m *metricSparkDriverExecutorGcOperations) init() {
	m.data.SetName("spark.driver.executor.gc.operations")
	m.data.SetDescription("Number of garbage collection operations performed by the driver.")
	m.data.SetUnit("{ gc_operation }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDriverExecutorGcOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, gcTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("gc_type", gcTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverExecutorGcOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverExecutorGcOperations) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverExecutorGcOperations(cfg MetricConfig) metricSparkDriverExecutorGcOperations {
	m := metricSparkDriverExecutorGcOperations{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverExecutorGcTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.executor.gc.time metric with initial data.
func (m *metricSparkDriverExecutorGcTime) init() {
	m.data.SetName("spark.driver.executor.gc.time")
	m.data.SetDescription("Total elapsed time during garbage collection operations performed by the driver.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDriverExecutorGcTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, gcTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("gc_type", gcTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverExecutorGcTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverExecutorGcTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverExecutorGcTime(cfg MetricConfig) metricSparkDriverExecutorGcTime {
	m := metricSparkDriverExecutorGcTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverExecutorMemoryExecution struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.executor.memory.execution metric with initial data.
func (m *metricSparkDriverExecutorMemoryExecution) init() {
	m.data.SetName("spark.driver.executor.memory.execution")
	m.data.SetDescription("Amount of execution memory currently used by the driver.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDriverExecutorMemoryExecution) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverExecutorMemoryExecution) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverExecutorMemoryExecution) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverExecutorMemoryExecution(cfg MetricConfig) metricSparkDriverExecutorMemoryExecution {
	m := metricSparkDriverExecutorMemoryExecution{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverExecutorMemoryJvm struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.executor.memory.jvm metric with initial data.
func (m *metricSparkDriverExecutorMemoryJvm) init() {
	m.data.SetName("spark.driver.executor.memory.jvm")
	m.data.SetDescription("Amount of memory used by the driver's JVM.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDriverExecutorMemoryJvm) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverExecutorMemoryJvm) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverExecutorMemoryJvm) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverExecutorMemoryJvm(cfg MetricConfig) metricSparkDriverExecutorMemoryJvm {
	m := metricSparkDriverExecutorMemoryJvm{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverExecutorMemoryPool struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.executor.memory.pool metric with initial data.
func (m *metricSparkDriverExecutorMemoryPool) init() {
	m.data.SetName("spark.driver.executor.memory.pool")
	m.data.SetDescription("Amount of pool memory currently used by the driver.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDriverExecutorMemoryPool) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, poolMemoryTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("type", poolMemoryTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverExecutorMemoryPool) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverExecutorMemoryPool) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverExecutorMemoryPool(cfg MetricConfig) metricSparkDriverExecutorMemoryPool {
	m := metricSparkDriverExecutorMemoryPool{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverExecutorMemoryStorage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.executor.memory.storage metric with initial data.
func (m *metricSparkDriverExecutorMemoryStorage) init() {
	m.data.SetName("spark.driver.executor.memory.storage")
	m.data.SetDescription("Amount of storage memory currently used by the driver.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDriverExecutorMemoryStorage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverExecutorMemoryStorage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverExecutorMemoryStorage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverExecutorMemoryStorage(cfg MetricConfig) metricSparkDriverExecutorMemoryStorage {
	m := metricSparkDriverExecutorMemoryStorage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverHiveExternalCatalogFileCacheHits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.hive_external_catalog.file_cache_hits metric with initial data.
func (m *metricSparkDriverHiveExternalCatalogFileCacheHits) init() {
	m.data.SetName("spark.driver.hive_external_catalog.file_cache_hits")
	m.data.SetDescription("Number of file cache hits on the HiveExternalCatalog.")
	m.data.SetUnit("{ hit }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverHiveExternalCatalogFileCacheHits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverHiveExternalCatalogFileCacheHits) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverHiveExternalCatalogFileCacheHits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverHiveExternalCatalogFileCacheHits(cfg MetricConfig) metricSparkDriverHiveExternalCatalogFileCacheHits {
	m := metricSparkDriverHiveExternalCatalogFileCacheHits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverHiveExternalCatalogFilesDiscovered struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.hive_external_catalog.files_discovered metric with initial data.
func (m *metricSparkDriverHiveExternalCatalogFilesDiscovered) init() {
	m.data.SetName("spark.driver.hive_external_catalog.files_discovered")
	m.data.SetDescription("Number of files discovered while listing the partitions of a table in the Hive metastore")
	m.data.SetUnit("{ file }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverHiveExternalCatalogFilesDiscovered) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverHiveExternalCatalogFilesDiscovered) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverHiveExternalCatalogFilesDiscovered) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverHiveExternalCatalogFilesDiscovered(cfg MetricConfig) metricSparkDriverHiveExternalCatalogFilesDiscovered {
	m := metricSparkDriverHiveExternalCatalogFilesDiscovered{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverHiveExternalCatalogHiveClientCalls struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.hive_external_catalog.hive_client_calls metric with initial data.
func (m *metricSparkDriverHiveExternalCatalogHiveClientCalls) init() {
	m.data.SetName("spark.driver.hive_external_catalog.hive_client_calls")
	m.data.SetDescription("Number of calls to the underlying Hive Metastore client made by the Spark application.")
	m.data.SetUnit("{ call }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverHiveExternalCatalogHiveClientCalls) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverHiveExternalCatalogHiveClientCalls) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverHiveExternalCatalogHiveClientCalls) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverHiveExternalCatalogHiveClientCalls(cfg MetricConfig) metricSparkDriverHiveExternalCatalogHiveClientCalls {
	m := metricSparkDriverHiveExternalCatalogHiveClientCalls{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverHiveExternalCatalogParallelListingJobs struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.hive_external_catalog.parallel_listing_jobs metric with initial data.
func (m *metricSparkDriverHiveExternalCatalogParallelListingJobs) init() {
	m.data.SetName("spark.driver.hive_external_catalog.parallel_listing_jobs")
	m.data.SetDescription("Number of parallel listing jobs initiated by the HiveExternalCatalog when listing partitions of a table.")
	m.data.SetUnit("{ listing_job }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverHiveExternalCatalogParallelListingJobs) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverHiveExternalCatalogParallelListingJobs) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverHiveExternalCatalogParallelListingJobs) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverHiveExternalCatalogParallelListingJobs(cfg MetricConfig) metricSparkDriverHiveExternalCatalogParallelListingJobs {
	m := metricSparkDriverHiveExternalCatalogParallelListingJobs{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverHiveExternalCatalogPartitionsFetched struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.hive_external_catalog.partitions_fetched metric with initial data.
func (m *metricSparkDriverHiveExternalCatalogPartitionsFetched) init() {
	m.data.SetName("spark.driver.hive_external_catalog.partitions_fetched")
	m.data.SetDescription("Table partitions fetched by the HiveExternalCatalog.")
	m.data.SetUnit("{ partition }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverHiveExternalCatalogPartitionsFetched) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverHiveExternalCatalogPartitionsFetched) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverHiveExternalCatalogPartitionsFetched) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverHiveExternalCatalogPartitionsFetched(cfg MetricConfig) metricSparkDriverHiveExternalCatalogPartitionsFetched {
	m := metricSparkDriverHiveExternalCatalogPartitionsFetched{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverJvmCPUTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.jvm_cpu_time metric with initial data.
func (m *metricSparkDriverJvmCPUTime) init() {
	m.data.SetName("spark.driver.jvm_cpu_time")
	m.data.SetDescription("Current CPU time taken by the Spark driver.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverJvmCPUTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverJvmCPUTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverJvmCPUTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverJvmCPUTime(cfg MetricConfig) metricSparkDriverJvmCPUTime {
	m := metricSparkDriverJvmCPUTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverLiveListenerBusDropped struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.live_listener_bus.dropped metric with initial data.
func (m *metricSparkDriverLiveListenerBusDropped) init() {
	m.data.SetName("spark.driver.live_listener_bus.dropped")
	m.data.SetDescription("Number of events that have been dropped by the LiveListenerBus.")
	m.data.SetUnit("{ event }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverLiveListenerBusDropped) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverLiveListenerBusDropped) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverLiveListenerBusDropped) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverLiveListenerBusDropped(cfg MetricConfig) metricSparkDriverLiveListenerBusDropped {
	m := metricSparkDriverLiveListenerBusDropped{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverLiveListenerBusPosted struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.live_listener_bus.posted metric with initial data.
func (m *metricSparkDriverLiveListenerBusPosted) init() {
	m.data.SetName("spark.driver.live_listener_bus.posted")
	m.data.SetDescription("Number of events that have been posted on the LiveListenerBus.")
	m.data.SetUnit("{ event }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverLiveListenerBusPosted) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverLiveListenerBusPosted) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverLiveListenerBusPosted) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverLiveListenerBusPosted(cfg MetricConfig) metricSparkDriverLiveListenerBusPosted {
	m := metricSparkDriverLiveListenerBusPosted{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverLiveListenerBusProcessingTimeAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.live_listener_bus.processing_time.average metric with initial data.
func (m *metricSparkDriverLiveListenerBusProcessingTimeAverage) init() {
	m.data.SetName("spark.driver.live_listener_bus.processing_time.average")
	m.data.SetDescription("Average time taken for the LiveListenerBus to process an event posted to it.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
}

func (m *metricSparkDriverLiveListenerBusProcessingTimeAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverLiveListenerBusProcessingTimeAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverLiveListenerBusProcessingTimeAverage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverLiveListenerBusProcessingTimeAverage(cfg MetricConfig) metricSparkDriverLiveListenerBusProcessingTimeAverage {
	m := metricSparkDriverLiveListenerBusProcessingTimeAverage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDriverLiveListenerBusQueueSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.driver.live_listener_bus.queue_size metric with initial data.
func (m *metricSparkDriverLiveListenerBusQueueSize) init() {
	m.data.SetName("spark.driver.live_listener_bus.queue_size")
	m.data.SetDescription("Number of events currently waiting to be processed by the LiveListenerBus.")
	m.data.SetUnit("{ event }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDriverLiveListenerBusQueueSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDriverLiveListenerBusQueueSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDriverLiveListenerBusQueueSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDriverLiveListenerBusQueueSize(cfg MetricConfig) metricSparkDriverLiveListenerBusQueueSize {
	m := metricSparkDriverLiveListenerBusQueueSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorDiskUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.disk.usage metric with initial data.
func (m *metricSparkExecutorDiskUsage) init() {
	m.data.SetName("spark.executor.disk.usage")
	m.data.SetDescription("Disk space used by this executor for RDD storage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorDiskUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorDiskUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorDiskUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorDiskUsage(cfg MetricConfig) metricSparkExecutorDiskUsage {
	m := metricSparkExecutorDiskUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorGcTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.gc_time metric with initial data.
func (m *metricSparkExecutorGcTime) init() {
	m.data.SetName("spark.executor.gc_time")
	m.data.SetDescription("Elapsed time the JVM spent in garbage collection in this executor.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorGcTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorGcTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorGcTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorGcTime(cfg MetricConfig) metricSparkExecutorGcTime {
	m := metricSparkExecutorGcTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorInputSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.input_size metric with initial data.
func (m *metricSparkExecutorInputSize) init() {
	m.data.SetName("spark.executor.input_size")
	m.data.SetDescription("Amount of data input for this executor.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorInputSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorInputSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorInputSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorInputSize(cfg MetricConfig) metricSparkExecutorInputSize {
	m := metricSparkExecutorInputSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorMemoryUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.memory.usage metric with initial data.
func (m *metricSparkExecutorMemoryUsage) init() {
	m.data.SetName("spark.executor.memory.usage")
	m.data.SetDescription("Storage memory used by this executor.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorMemoryUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorMemoryUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorMemoryUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorMemoryUsage(cfg MetricConfig) metricSparkExecutorMemoryUsage {
	m := metricSparkExecutorMemoryUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorShuffleIoSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.shuffle.io.size metric with initial data.
func (m *metricSparkExecutorShuffleIoSize) init() {
	m.data.SetName("spark.executor.shuffle.io.size")
	m.data.SetDescription("Amount of data written and read during shuffle operations for this executor.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorShuffleIoSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorShuffleIoSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorShuffleIoSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorShuffleIoSize(cfg MetricConfig) metricSparkExecutorShuffleIoSize {
	m := metricSparkExecutorShuffleIoSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorStorageMemoryUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.storage_memory.usage metric with initial data.
func (m *metricSparkExecutorStorageMemoryUsage) init() {
	m.data.SetName("spark.executor.storage_memory.usage")
	m.data.SetDescription("The executor's storage memory usage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorStorageMemoryUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string, stateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
	dp.Attributes().PutStr("state", stateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorStorageMemoryUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorStorageMemoryUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorStorageMemoryUsage(cfg MetricConfig) metricSparkExecutorStorageMemoryUsage {
	m := metricSparkExecutorStorageMemoryUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorTaskActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.task.active metric with initial data.
func (m *metricSparkExecutorTaskActive) init() {
	m.data.SetName("spark.executor.task.active")
	m.data.SetDescription("Number of tasks currently running in this executor.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorTaskActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorTaskActive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorTaskActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorTaskActive(cfg MetricConfig) metricSparkExecutorTaskActive {
	m := metricSparkExecutorTaskActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorTaskLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.task.limit metric with initial data.
func (m *metricSparkExecutorTaskLimit) init() {
	m.data.SetName("spark.executor.task.limit")
	m.data.SetDescription("Maximum number of tasks that can run concurrently in this executor.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorTaskLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorTaskLimit) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorTaskLimit) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorTaskLimit(cfg MetricConfig) metricSparkExecutorTaskLimit {
	m := metricSparkExecutorTaskLimit{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorTaskResult struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.task.result metric with initial data.
func (m *metricSparkExecutorTaskResult) init() {
	m.data.SetName("spark.executor.task.result")
	m.data.SetDescription("Number of tasks with a specific result in this executor.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorTaskResult) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, executorTaskResultAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("result", executorTaskResultAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorTaskResult) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorTaskResult) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorTaskResult(cfg MetricConfig) metricSparkExecutorTaskResult {
	m := metricSparkExecutorTaskResult{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.time metric with initial data.
func (m *metricSparkExecutorTime) init() {
	m.data.SetName("spark.executor.time")
	m.data.SetDescription("Elapsed time the JVM spent executing tasks in this executor.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorTime(cfg MetricConfig) metricSparkExecutorTime {
	m := metricSparkExecutorTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkJobStageActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.job.stage.active metric with initial data.
func (m *metricSparkJobStageActive) init() {
	m.data.SetName("spark.job.stage.active")
	m.data.SetDescription("Number of active stages in this job.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkJobStageActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkJobStageActive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkJobStageActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkJobStageActive(cfg MetricConfig) metricSparkJobStageActive {
	m := metricSparkJobStageActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkJobStageResult struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.job.stage.result metric with initial data.
func (m *metricSparkJobStageResult) init() {
	m.data.SetName("spark.job.stage.result")
	m.data.SetDescription("Number of stages with a specific result in this job.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkJobStageResult) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, jobResultAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("result", jobResultAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkJobStageResult) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkJobStageResult) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkJobStageResult(cfg MetricConfig) metricSparkJobStageResult {
	m := metricSparkJobStageResult{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkJobTaskActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.job.task.active metric with initial data.
func (m *metricSparkJobTaskActive) init() {
	m.data.SetName("spark.job.task.active")
	m.data.SetDescription("Number of active tasks in this job.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkJobTaskActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkJobTaskActive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkJobTaskActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkJobTaskActive(cfg MetricConfig) metricSparkJobTaskActive {
	m := metricSparkJobTaskActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkJobTaskResult struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.job.task.result metric with initial data.
func (m *metricSparkJobTaskResult) init() {
	m.data.SetName("spark.job.task.result")
	m.data.SetDescription("Number of tasks with a specific result in this job.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkJobTaskResult) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, jobResultAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("result", jobResultAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkJobTaskResult) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkJobTaskResult) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkJobTaskResult(cfg MetricConfig) metricSparkJobTaskResult {
	m := metricSparkJobTaskResult{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageDiskSpilled struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.disk.spilled metric with initial data.
func (m *metricSparkStageDiskSpilled) init() {
	m.data.SetName("spark.stage.disk.spilled")
	m.data.SetDescription("The amount of disk space used for storing portions of overly large data chunks that couldn't fit in memory in this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkStageDiskSpilled) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageDiskSpilled) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageDiskSpilled) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageDiskSpilled(cfg MetricConfig) metricSparkStageDiskSpilled {
	m := metricSparkStageDiskSpilled{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageExecutorCPUTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.executor.cpu_time metric with initial data.
func (m *metricSparkStageExecutorCPUTime) init() {
	m.data.SetName("spark.stage.executor.cpu_time")
	m.data.SetDescription("CPU time spent by the executor in this stage.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkStageExecutorCPUTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageExecutorCPUTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageExecutorCPUTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageExecutorCPUTime(cfg MetricConfig) metricSparkStageExecutorCPUTime {
	m := metricSparkStageExecutorCPUTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageExecutorRunTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.executor.run_time metric with initial data.
func (m *metricSparkStageExecutorRunTime) init() {
	m.data.SetName("spark.stage.executor.run_time")
	m.data.SetDescription("Amount of time spent by the executor in this stage.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkStageExecutorRunTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageExecutorRunTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageExecutorRunTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageExecutorRunTime(cfg MetricConfig) metricSparkStageExecutorRunTime {
	m := metricSparkStageExecutorRunTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageIoRecords struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.io.records metric with initial data.
func (m *metricSparkStageIoRecords) init() {
	m.data.SetName("spark.stage.io.records")
	m.data.SetDescription("Number of records written and read in this stage.")
	m.data.SetUnit("{ record }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageIoRecords) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageIoRecords) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageIoRecords) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageIoRecords(cfg MetricConfig) metricSparkStageIoRecords {
	m := metricSparkStageIoRecords{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageIoSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.io.size metric with initial data.
func (m *metricSparkStageIoSize) init() {
	m.data.SetName("spark.stage.io.size")
	m.data.SetDescription("Amount of data written and read at this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageIoSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageIoSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageIoSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageIoSize(cfg MetricConfig) metricSparkStageIoSize {
	m := metricSparkStageIoSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageJvmGcTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.jvm_gc_time metric with initial data.
func (m *metricSparkStageJvmGcTime) init() {
	m.data.SetName("spark.stage.jvm_gc_time")
	m.data.SetDescription("The amount of time the JVM spent on garbage collection in this stage.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkStageJvmGcTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageJvmGcTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageJvmGcTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageJvmGcTime(cfg MetricConfig) metricSparkStageJvmGcTime {
	m := metricSparkStageJvmGcTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageMemoryPeak struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.memory.peak metric with initial data.
func (m *metricSparkStageMemoryPeak) init() {
	m.data.SetName("spark.stage.memory.peak")
	m.data.SetDescription("Peak memory used by internal data structures created during shuffles, aggregations and joins in this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkStageMemoryPeak) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageMemoryPeak) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageMemoryPeak) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageMemoryPeak(cfg MetricConfig) metricSparkStageMemoryPeak {
	m := metricSparkStageMemoryPeak{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageMemorySpilled struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.memory.spilled metric with initial data.
func (m *metricSparkStageMemorySpilled) init() {
	m.data.SetName("spark.stage.memory.spilled")
	m.data.SetDescription("The amount of memory moved to disk due to size constraints (spilled) in this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkStageMemorySpilled) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageMemorySpilled) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageMemorySpilled) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageMemorySpilled(cfg MetricConfig) metricSparkStageMemorySpilled {
	m := metricSparkStageMemorySpilled{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleBlocksFetched struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.blocks_fetched metric with initial data.
func (m *metricSparkStageShuffleBlocksFetched) init() {
	m.data.SetName("spark.stage.shuffle.blocks_fetched")
	m.data.SetDescription("Number of blocks fetched in shuffle operations in this stage.")
	m.data.SetUnit("{ block }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageShuffleBlocksFetched) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, sourceAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("source", sourceAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleBlocksFetched) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleBlocksFetched) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleBlocksFetched(cfg MetricConfig) metricSparkStageShuffleBlocksFetched {
	m := metricSparkStageShuffleBlocksFetched{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleFetchWaitTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.fetch_wait_time metric with initial data.
func (m *metricSparkStageShuffleFetchWaitTime) init() {
	m.data.SetName("spark.stage.shuffle.fetch_wait_time")
	m.data.SetDescription("Time spent in this stage waiting for remote shuffle blocks.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkStageShuffleFetchWaitTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleFetchWaitTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleFetchWaitTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleFetchWaitTime(cfg MetricConfig) metricSparkStageShuffleFetchWaitTime {
	m := metricSparkStageShuffleFetchWaitTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleIoDisk struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.io.disk metric with initial data.
func (m *metricSparkStageShuffleIoDisk) init() {
	m.data.SetName("spark.stage.shuffle.io.disk")
	m.data.SetDescription("Amount of data read to disk in shuffle operations (sometimes required for large blocks, as opposed to the default behavior of reading into memory).")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkStageShuffleIoDisk) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleIoDisk) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleIoDisk) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleIoDisk(cfg MetricConfig) metricSparkStageShuffleIoDisk {
	m := metricSparkStageShuffleIoDisk{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleIoReadSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.io.read.size metric with initial data.
func (m *metricSparkStageShuffleIoReadSize) init() {
	m.data.SetName("spark.stage.shuffle.io.read.size")
	m.data.SetDescription("Amount of data read in shuffle operations in this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageShuffleIoReadSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, sourceAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("source", sourceAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleIoReadSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleIoReadSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleIoReadSize(cfg MetricConfig) metricSparkStageShuffleIoReadSize {
	m := metricSparkStageShuffleIoReadSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleIoRecords struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.io.records metric with initial data.
func (m *metricSparkStageShuffleIoRecords) init() {
	m.data.SetName("spark.stage.shuffle.io.records")
	m.data.SetDescription("Number of records written or read in shuffle operations in this stage.")
	m.data.SetUnit("{ record }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageShuffleIoRecords) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleIoRecords) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleIoRecords) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleIoRecords(cfg MetricConfig) metricSparkStageShuffleIoRecords {
	m := metricSparkStageShuffleIoRecords{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleIoWriteSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.io.write.size metric with initial data.
func (m *metricSparkStageShuffleIoWriteSize) init() {
	m.data.SetName("spark.stage.shuffle.io.write.size")
	m.data.SetDescription("Amount of data written in shuffle operations in this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkStageShuffleIoWriteSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleIoWriteSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleIoWriteSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleIoWriteSize(cfg MetricConfig) metricSparkStageShuffleIoWriteSize {
	m := metricSparkStageShuffleIoWriteSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleWriteTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.write_time metric with initial data.
func (m *metricSparkStageShuffleWriteTime) init() {
	m.data.SetName("spark.stage.shuffle.write_time")
	m.data.SetDescription("Time spent blocking on writes to disk or buffer cache in this stage.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkStageShuffleWriteTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleWriteTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleWriteTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleWriteTime(cfg MetricConfig) metricSparkStageShuffleWriteTime {
	m := metricSparkStageShuffleWriteTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageStatus struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.status metric with initial data.
func (m *metricSparkStageStatus) init() {
	m.data.SetName("spark.stage.status")
	m.data.SetDescription("A one-hot encoding representing the status of this stage.")
	m.data.SetUnit("{ status }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageStatus) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutBool("active", stageActiveAttributeValue)
	dp.Attributes().PutBool("complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageStatus) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageStatus) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageStatus(cfg MetricConfig) metricSparkStageStatus {
	m := metricSparkStageStatus{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageTaskActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.task.active metric with initial data.
func (m *metricSparkStageTaskActive) init() {
	m.data.SetName("spark.stage.task.active")
	m.data.SetDescription("Number of active tasks in this stage.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkStageTaskActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageTaskActive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageTaskActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageTaskActive(cfg MetricConfig) metricSparkStageTaskActive {
	m := metricSparkStageTaskActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageTaskResult struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.task.result metric with initial data.
func (m *metricSparkStageTaskResult) init() {
	m.data.SetName("spark.stage.task.result")
	m.data.SetDescription("Number of tasks with a specific result in this stage.")
	m.data.SetUnit("{ task }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageTaskResult) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, stageTaskResultAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("result", stageTaskResultAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageTaskResult) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageTaskResult) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageTaskResult(cfg MetricConfig) metricSparkStageTaskResult {
	m := metricSparkStageTaskResult{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageTaskResultSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.task.result_size metric with initial data.
func (m *metricSparkStageTaskResultSize) init() {
	m.data.SetName("spark.stage.task.result_size")
	m.data.SetDescription("The amount of data transmitted back to the driver by all the tasks in this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkStageTaskResultSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageTaskResultSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageTaskResultSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageTaskResultSize(cfg MetricConfig) metricSparkStageTaskResultSize {
	m := metricSparkStageTaskResultSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// missedEmitsToDropRMB is number of missed emits after which resource builder will be dropped from MetricsBuilder.rmbMap.
// Potentially, this value can be made configurable through a MetricsBuilder option.
const missedEmitsToDropRMB = 5

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config    MetricsBuilderConfig                 // config of the metrics builder.
	buildInfo component.BuildInfo                  // contains version information
	startTime pcommon.Timestamp                    // start time that will be applied to all recorded data points.
	rmbMap    map[[16]byte]*ResourceMetricsBuilder // map of resource builders by resource hash.
}

type ResourceMetricsBuilder struct {
	buildInfo                                                component.BuildInfo
	startTime                                                pcommon.Timestamp // start time that will be applied to all recorded data points.
	metricsCapacity                                          int               // maximum observed number of metrics per resource.
	resource                                                 pcommon.Resource
	missedEmits                                              int
	metricSparkDriverBlockManagerDiskUsage                   metricSparkDriverBlockManagerDiskUsage
	metricSparkDriverBlockManagerMemoryUsage                 metricSparkDriverBlockManagerMemoryUsage
	metricSparkDriverCodeGeneratorCompilationAverageTime     metricSparkDriverCodeGeneratorCompilationAverageTime
	metricSparkDriverCodeGeneratorCompilationCount           metricSparkDriverCodeGeneratorCompilationCount
	metricSparkDriverCodeGeneratorGeneratedClassAverageSize  metricSparkDriverCodeGeneratorGeneratedClassAverageSize
	metricSparkDriverCodeGeneratorGeneratedClassCount        metricSparkDriverCodeGeneratorGeneratedClassCount
	metricSparkDriverCodeGeneratorGeneratedMethodAverageSize metricSparkDriverCodeGeneratorGeneratedMethodAverageSize
	metricSparkDriverCodeGeneratorGeneratedMethodCount       metricSparkDriverCodeGeneratorGeneratedMethodCount
	metricSparkDriverCodeGeneratorSourceCodeAverageSize      metricSparkDriverCodeGeneratorSourceCodeAverageSize
	metricSparkDriverCodeGeneratorSourceCodeOperations       metricSparkDriverCodeGeneratorSourceCodeOperations
	metricSparkDriverDagSchedulerJobActive                   metricSparkDriverDagSchedulerJobActive
	metricSparkDriverDagSchedulerJobCount                    metricSparkDriverDagSchedulerJobCount
	metricSparkDriverDagSchedulerStageCount                  metricSparkDriverDagSchedulerStageCount
	metricSparkDriverDagSchedulerStageFailed                 metricSparkDriverDagSchedulerStageFailed
	metricSparkDriverExecutorGcOperations                    metricSparkDriverExecutorGcOperations
	metricSparkDriverExecutorGcTime                          metricSparkDriverExecutorGcTime
	metricSparkDriverExecutorMemoryExecution                 metricSparkDriverExecutorMemoryExecution
	metricSparkDriverExecutorMemoryJvm                       metricSparkDriverExecutorMemoryJvm
	metricSparkDriverExecutorMemoryPool                      metricSparkDriverExecutorMemoryPool
	metricSparkDriverExecutorMemoryStorage                   metricSparkDriverExecutorMemoryStorage
	metricSparkDriverHiveExternalCatalogFileCacheHits        metricSparkDriverHiveExternalCatalogFileCacheHits
	metricSparkDriverHiveExternalCatalogFilesDiscovered      metricSparkDriverHiveExternalCatalogFilesDiscovered
	metricSparkDriverHiveExternalCatalogHiveClientCalls      metricSparkDriverHiveExternalCatalogHiveClientCalls
	metricSparkDriverHiveExternalCatalogParallelListingJobs  metricSparkDriverHiveExternalCatalogParallelListingJobs
	metricSparkDriverHiveExternalCatalogPartitionsFetched    metricSparkDriverHiveExternalCatalogPartitionsFetched
	metricSparkDriverJvmCPUTime                              metricSparkDriverJvmCPUTime
	metricSparkDriverLiveListenerBusDropped                  metricSparkDriverLiveListenerBusDropped
	metricSparkDriverLiveListenerBusPosted                   metricSparkDriverLiveListenerBusPosted
	metricSparkDriverLiveListenerBusProcessingTimeAverage    metricSparkDriverLiveListenerBusProcessingTimeAverage
	metricSparkDriverLiveListenerBusQueueSize                metricSparkDriverLiveListenerBusQueueSize
	metricSparkExecutorDiskUsage                             metricSparkExecutorDiskUsage
	metricSparkExecutorGcTime                                metricSparkExecutorGcTime
	metricSparkExecutorInputSize                             metricSparkExecutorInputSize
	metricSparkExecutorMemoryUsage                           metricSparkExecutorMemoryUsage
	metricSparkExecutorShuffleIoSize                         metricSparkExecutorShuffleIoSize
	metricSparkExecutorStorageMemoryUsage                    metricSparkExecutorStorageMemoryUsage
	metricSparkExecutorTaskActive                            metricSparkExecutorTaskActive
	metricSparkExecutorTaskLimit                             metricSparkExecutorTaskLimit
	metricSparkExecutorTaskResult                            metricSparkExecutorTaskResult
	metricSparkExecutorTime                                  metricSparkExecutorTime
	metricSparkJobStageActive                                metricSparkJobStageActive
	metricSparkJobStageResult                                metricSparkJobStageResult
	metricSparkJobTaskActive                                 metricSparkJobTaskActive
	metricSparkJobTaskResult                                 metricSparkJobTaskResult
	metricSparkStageDiskSpilled                              metricSparkStageDiskSpilled
	metricSparkStageExecutorCPUTime                          metricSparkStageExecutorCPUTime
	metricSparkStageExecutorRunTime                          metricSparkStageExecutorRunTime
	metricSparkStageIoRecords                                metricSparkStageIoRecords
	metricSparkStageIoSize                                   metricSparkStageIoSize
	metricSparkStageJvmGcTime                                metricSparkStageJvmGcTime
	metricSparkStageMemoryPeak                               metricSparkStageMemoryPeak
	metricSparkStageMemorySpilled                            metricSparkStageMemorySpilled
	metricSparkStageShuffleBlocksFetched                     metricSparkStageShuffleBlocksFetched
	metricSparkStageShuffleFetchWaitTime                     metricSparkStageShuffleFetchWaitTime
	metricSparkStageShuffleIoDisk                            metricSparkStageShuffleIoDisk
	metricSparkStageShuffleIoReadSize                        metricSparkStageShuffleIoReadSize
	metricSparkStageShuffleIoRecords                         metricSparkStageShuffleIoRecords
	metricSparkStageShuffleIoWriteSize                       metricSparkStageShuffleIoWriteSize
	metricSparkStageShuffleWriteTime                         metricSparkStageShuffleWriteTime
	metricSparkStageStatus                                   metricSparkStageStatus
	metricSparkStageTaskActive                               metricSparkStageTaskActive
	metricSparkStageTaskResult                               metricSparkStageTaskResult
	metricSparkStageTaskResultSize                           metricSparkStageTaskResultSize
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.CreateSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:    mbc,
		startTime: pcommon.NewTimestampFromTime(time.Now()),
		buildInfo: settings.BuildInfo,
		rmbMap:    make(map[[16]byte]*ResourceMetricsBuilder),
	}
	for _, opt := range options {
		opt(mb)
	}
	return mb
}

// resourceMetricsBuilderOption applies changes to provided resource metrics.
type resourceMetricsBuilderOption func(*ResourceMetricsBuilder)

// WithStartTimeOverride sets start time for all the resource metrics data points.
func WithStartTimeOverride(start pcommon.Timestamp) resourceMetricsBuilderOption {
	return func(rmb *ResourceMetricsBuilder) {
		rmb.startTime = start
	}
}

// ResourceMetricsBuilder returns a ResourceMetricsBuilder that can be used to record metrics for a specific resource.
// It requires Resource to be provided which should be built with ResourceBuilder.
func (mb *MetricsBuilder) ResourceMetricsBuilder(res pcommon.Resource, options ...resourceMetricsBuilderOption) *ResourceMetricsBuilder {
	hash := pdatautil.MapHash(res.Attributes())
	if rmb, ok := mb.rmbMap[hash]; ok {
		return rmb
	}
	rmb := &ResourceMetricsBuilder{
		startTime:                                mb.startTime,
		buildInfo:                                mb.buildInfo,
		resource:                                 res,
		metricSparkDriverBlockManagerDiskUsage:   newMetricSparkDriverBlockManagerDiskUsage(mb.config.Metrics.SparkDriverBlockManagerDiskUsage),
		metricSparkDriverBlockManagerMemoryUsage: newMetricSparkDriverBlockManagerMemoryUsage(mb.config.Metrics.SparkDriverBlockManagerMemoryUsage),
		metricSparkDriverCodeGeneratorCompilationAverageTime:     newMetricSparkDriverCodeGeneratorCompilationAverageTime(mb.config.Metrics.SparkDriverCodeGeneratorCompilationAverageTime),
		metricSparkDriverCodeGeneratorCompilationCount:           newMetricSparkDriverCodeGeneratorCompilationCount(mb.config.Metrics.SparkDriverCodeGeneratorCompilationCount),
		metricSparkDriverCodeGeneratorGeneratedClassAverageSize:  newMetricSparkDriverCodeGeneratorGeneratedClassAverageSize(mb.config.Metrics.SparkDriverCodeGeneratorGeneratedClassAverageSize),
		metricSparkDriverCodeGeneratorGeneratedClassCount:        newMetricSparkDriverCodeGeneratorGeneratedClassCount(mb.config.Metrics.SparkDriverCodeGeneratorGeneratedClassCount),
		metricSparkDriverCodeGeneratorGeneratedMethodAverageSize: newMetricSparkDriverCodeGeneratorGeneratedMethodAverageSize(mb.config.Metrics.SparkDriverCodeGeneratorGeneratedMethodAverageSize),
		metricSparkDriverCodeGeneratorGeneratedMethodCount:       newMetricSparkDriverCodeGeneratorGeneratedMethodCount(mb.config.Metrics.SparkDriverCodeGeneratorGeneratedMethodCount),
		metricSparkDriverCodeGeneratorSourceCodeAverageSize:      newMetricSparkDriverCodeGeneratorSourceCodeAverageSize(mb.config.Metrics.SparkDriverCodeGeneratorSourceCodeAverageSize),
		metricSparkDriverCodeGeneratorSourceCodeOperations:       newMetricSparkDriverCodeGeneratorSourceCodeOperations(mb.config.Metrics.SparkDriverCodeGeneratorSourceCodeOperations),
		metricSparkDriverDagSchedulerJobActive:                   newMetricSparkDriverDagSchedulerJobActive(mb.config.Metrics.SparkDriverDagSchedulerJobActive),
		metricSparkDriverDagSchedulerJobCount:                    newMetricSparkDriverDagSchedulerJobCount(mb.config.Metrics.SparkDriverDagSchedulerJobCount),
		metricSparkDriverDagSchedulerStageCount:                  newMetricSparkDriverDagSchedulerStageCount(mb.config.Metrics.SparkDriverDagSchedulerStageCount),
		metricSparkDriverDagSchedulerStageFailed:                 newMetricSparkDriverDagSchedulerStageFailed(mb.config.Metrics.SparkDriverDagSchedulerStageFailed),
		metricSparkDriverExecutorGcOperations:                    newMetricSparkDriverExecutorGcOperations(mb.config.Metrics.SparkDriverExecutorGcOperations),
		metricSparkDriverExecutorGcTime:                          newMetricSparkDriverExecutorGcTime(mb.config.Metrics.SparkDriverExecutorGcTime),
		metricSparkDriverExecutorMemoryExecution:                 newMetricSparkDriverExecutorMemoryExecution(mb.config.Metrics.SparkDriverExecutorMemoryExecution),
		metricSparkDriverExecutorMemoryJvm:                       newMetricSparkDriverExecutorMemoryJvm(mb.config.Metrics.SparkDriverExecutorMemoryJvm),
		metricSparkDriverExecutorMemoryPool:                      newMetricSparkDriverExecutorMemoryPool(mb.config.Metrics.SparkDriverExecutorMemoryPool),
		metricSparkDriverExecutorMemoryStorage:                   newMetricSparkDriverExecutorMemoryStorage(mb.config.Metrics.SparkDriverExecutorMemoryStorage),
		metricSparkDriverHiveExternalCatalogFileCacheHits:        newMetricSparkDriverHiveExternalCatalogFileCacheHits(mb.config.Metrics.SparkDriverHiveExternalCatalogFileCacheHits),
		metricSparkDriverHiveExternalCatalogFilesDiscovered:      newMetricSparkDriverHiveExternalCatalogFilesDiscovered(mb.config.Metrics.SparkDriverHiveExternalCatalogFilesDiscovered),
		metricSparkDriverHiveExternalCatalogHiveClientCalls:      newMetricSparkDriverHiveExternalCatalogHiveClientCalls(mb.config.Metrics.SparkDriverHiveExternalCatalogHiveClientCalls),
		metricSparkDriverHiveExternalCatalogParallelListingJobs:  newMetricSparkDriverHiveExternalCatalogParallelListingJobs(mb.config.Metrics.SparkDriverHiveExternalCatalogParallelListingJobs),
		metricSparkDriverHiveExternalCatalogPartitionsFetched:    newMetricSparkDriverHiveExternalCatalogPartitionsFetched(mb.config.Metrics.SparkDriverHiveExternalCatalogPartitionsFetched),
		metricSparkDriverJvmCPUTime:                              newMetricSparkDriverJvmCPUTime(mb.config.Metrics.SparkDriverJvmCPUTime),
		metricSparkDriverLiveListenerBusDropped:                  newMetricSparkDriverLiveListenerBusDropped(mb.config.Metrics.SparkDriverLiveListenerBusDropped),
		metricSparkDriverLiveListenerBusPosted:                   newMetricSparkDriverLiveListenerBusPosted(mb.config.Metrics.SparkDriverLiveListenerBusPosted),
		metricSparkDriverLiveListenerBusProcessingTimeAverage:    newMetricSparkDriverLiveListenerBusProcessingTimeAverage(mb.config.Metrics.SparkDriverLiveListenerBusProcessingTimeAverage),
		metricSparkDriverLiveListenerBusQueueSize:                newMetricSparkDriverLiveListenerBusQueueSize(mb.config.Metrics.SparkDriverLiveListenerBusQueueSize),
		metricSparkExecutorDiskUsage:                             newMetricSparkExecutorDiskUsage(mb.config.Metrics.SparkExecutorDiskUsage),
		metricSparkExecutorGcTime:                                newMetricSparkExecutorGcTime(mb.config.Metrics.SparkExecutorGcTime),
		metricSparkExecutorInputSize:                             newMetricSparkExecutorInputSize(mb.config.Metrics.SparkExecutorInputSize),
		metricSparkExecutorMemoryUsage:                           newMetricSparkExecutorMemoryUsage(mb.config.Metrics.SparkExecutorMemoryUsage),
		metricSparkExecutorShuffleIoSize:                         newMetricSparkExecutorShuffleIoSize(mb.config.Metrics.SparkExecutorShuffleIoSize),
		metricSparkExecutorStorageMemoryUsage:                    newMetricSparkExecutorStorageMemoryUsage(mb.config.Metrics.SparkExecutorStorageMemoryUsage),
		metricSparkExecutorTaskActive:                            newMetricSparkExecutorTaskActive(mb.config.Metrics.SparkExecutorTaskActive),
		metricSparkExecutorTaskLimit:                             newMetricSparkExecutorTaskLimit(mb.config.Metrics.SparkExecutorTaskLimit),
		metricSparkExecutorTaskResult:                            newMetricSparkExecutorTaskResult(mb.config.Metrics.SparkExecutorTaskResult),
		metricSparkExecutorTime:                                  newMetricSparkExecutorTime(mb.config.Metrics.SparkExecutorTime),
		metricSparkJobStageActive:                                newMetricSparkJobStageActive(mb.config.Metrics.SparkJobStageActive),
		metricSparkJobStageResult:                                newMetricSparkJobStageResult(mb.config.Metrics.SparkJobStageResult),
		metricSparkJobTaskActive:                                 newMetricSparkJobTaskActive(mb.config.Metrics.SparkJobTaskActive),
		metricSparkJobTaskResult:                                 newMetricSparkJobTaskResult(mb.config.Metrics.SparkJobTaskResult),
		metricSparkStageDiskSpilled:                              newMetricSparkStageDiskSpilled(mb.config.Metrics.SparkStageDiskSpilled),
		metricSparkStageExecutorCPUTime:                          newMetricSparkStageExecutorCPUTime(mb.config.Metrics.SparkStageExecutorCPUTime),
		metricSparkStageExecutorRunTime:                          newMetricSparkStageExecutorRunTime(mb.config.Metrics.SparkStageExecutorRunTime),
		metricSparkStageIoRecords:                                newMetricSparkStageIoRecords(mb.config.Metrics.SparkStageIoRecords),
		metricSparkStageIoSize:                                   newMetricSparkStageIoSize(mb.config.Metrics.SparkStageIoSize),
		metricSparkStageJvmGcTime:                                newMetricSparkStageJvmGcTime(mb.config.Metrics.SparkStageJvmGcTime),
		metricSparkStageMemoryPeak:                               newMetricSparkStageMemoryPeak(mb.config.Metrics.SparkStageMemoryPeak),
		metricSparkStageMemorySpilled:                            newMetricSparkStageMemorySpilled(mb.config.Metrics.SparkStageMemorySpilled),
		metricSparkStageShuffleBlocksFetched:                     newMetricSparkStageShuffleBlocksFetched(mb.config.Metrics.SparkStageShuffleBlocksFetched),
		metricSparkStageShuffleFetchWaitTime:                     newMetricSparkStageShuffleFetchWaitTime(mb.config.Metrics.SparkStageShuffleFetchWaitTime),
		metricSparkStageShuffleIoDisk:                            newMetricSparkStageShuffleIoDisk(mb.config.Metrics.SparkStageShuffleIoDisk),
		metricSparkStageShuffleIoReadSize:                        newMetricSparkStageShuffleIoReadSize(mb.config.Metrics.SparkStageShuffleIoReadSize),
		metricSparkStageShuffleIoRecords:                         newMetricSparkStageShuffleIoRecords(mb.config.Metrics.SparkStageShuffleIoRecords),
		metricSparkStageShuffleIoWriteSize:                       newMetricSparkStageShuffleIoWriteSize(mb.config.Metrics.SparkStageShuffleIoWriteSize),
		metricSparkStageShuffleWriteTime:                         newMetricSparkStageShuffleWriteTime(mb.config.Metrics.SparkStageShuffleWriteTime),
		metricSparkStageStatus:                                   newMetricSparkStageStatus(mb.config.Metrics.SparkStageStatus),
		metricSparkStageTaskActive:                               newMetricSparkStageTaskActive(mb.config.Metrics.SparkStageTaskActive),
		metricSparkStageTaskResult:                               newMetricSparkStageTaskResult(mb.config.Metrics.SparkStageTaskResult),
		metricSparkStageTaskResultSize:                           newMetricSparkStageTaskResultSize(mb.config.Metrics.SparkStageTaskResultSize),
	}
	for _, op := range options {
		op(rmb)
	}
	mb.rmbMap[hash] = rmb
	return rmb
}

// NewResourceBuilder returns a new resource builder that should be used to build a resource associated with for the emitted metrics.
func (mb *MetricsBuilder) NewResourceBuilder() *ResourceBuilder {
	return NewResourceBuilder(mb.config.ResourceAttributes)
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (rmb *ResourceMetricsBuilder) updateCapacity(ms pmetric.MetricSlice) {
	if rmb.metricsCapacity < ms.Len() {
		rmb.metricsCapacity = ms.Len()
	}
}

// emit emits all the metrics accumulated by the ResourceMetricsBuilder and updates the internal state to be ready for
// recording another set of metrics. It returns true if any metrics were emitted.
func (rmb *ResourceMetricsBuilder) emit(m pmetric.Metrics) bool {
	sm := pmetric.NewScopeMetrics()
	sm.Metrics().EnsureCapacity(rmb.metricsCapacity)
	rmb.metricSparkDriverBlockManagerDiskUsage.emit(sm.Metrics())
	rmb.metricSparkDriverBlockManagerMemoryUsage.emit(sm.Metrics())
	rmb.metricSparkDriverCodeGeneratorCompilationAverageTime.emit(sm.Metrics())
	rmb.metricSparkDriverCodeGeneratorCompilationCount.emit(sm.Metrics())
	rmb.metricSparkDriverCodeGeneratorGeneratedClassAverageSize.emit(sm.Metrics())
	rmb.metricSparkDriverCodeGeneratorGeneratedClassCount.emit(sm.Metrics())
	rmb.metricSparkDriverCodeGeneratorGeneratedMethodAverageSize.emit(sm.Metrics())
	rmb.metricSparkDriverCodeGeneratorGeneratedMethodCount.emit(sm.Metrics())
	rmb.metricSparkDriverCodeGeneratorSourceCodeAverageSize.emit(sm.Metrics())
	rmb.metricSparkDriverCodeGeneratorSourceCodeOperations.emit(sm.Metrics())
	rmb.metricSparkDriverDagSchedulerJobActive.emit(sm.Metrics())
	rmb.metricSparkDriverDagSchedulerJobCount.emit(sm.Metrics())
	rmb.metricSparkDriverDagSchedulerStageCount.emit(sm.Metrics())
	rmb.metricSparkDriverDagSchedulerStageFailed.emit(sm.Metrics())
	rmb.metricSparkDriverExecutorGcOperations.emit(sm.Metrics())
	rmb.metricSparkDriverExecutorGcTime.emit(sm.Metrics())
	rmb.metricSparkDriverExecutorMemoryExecution.emit(sm.Metrics())
	rmb.metricSparkDriverExecutorMemoryJvm.emit(sm.Metrics())
	rmb.metricSparkDriverExecutorMemoryPool.emit(sm.Metrics())
	rmb.metricSparkDriverExecutorMemoryStorage.emit(sm.Metrics())
	rmb.metricSparkDriverHiveExternalCatalogFileCacheHits.emit(sm.Metrics())
	rmb.metricSparkDriverHiveExternalCatalogFilesDiscovered.emit(sm.Metrics())
	rmb.metricSparkDriverHiveExternalCatalogHiveClientCalls.emit(sm.Metrics())
	rmb.metricSparkDriverHiveExternalCatalogParallelListingJobs.emit(sm.Metrics())
	rmb.metricSparkDriverHiveExternalCatalogPartitionsFetched.emit(sm.Metrics())
	rmb.metricSparkDriverJvmCPUTime.emit(sm.Metrics())
	rmb.metricSparkDriverLiveListenerBusDropped.emit(sm.Metrics())
	rmb.metricSparkDriverLiveListenerBusPosted.emit(sm.Metrics())
	rmb.metricSparkDriverLiveListenerBusProcessingTimeAverage.emit(sm.Metrics())
	rmb.metricSparkDriverLiveListenerBusQueueSize.emit(sm.Metrics())
	rmb.metricSparkExecutorDiskUsage.emit(sm.Metrics())
	rmb.metricSparkExecutorGcTime.emit(sm.Metrics())
	rmb.metricSparkExecutorInputSize.emit(sm.Metrics())
	rmb.metricSparkExecutorMemoryUsage.emit(sm.Metrics())
	rmb.metricSparkExecutorShuffleIoSize.emit(sm.Metrics())
	rmb.metricSparkExecutorStorageMemoryUsage.emit(sm.Metrics())
	rmb.metricSparkExecutorTaskActive.emit(sm.Metrics())
	rmb.metricSparkExecutorTaskLimit.emit(sm.Metrics())
	rmb.metricSparkExecutorTaskResult.emit(sm.Metrics())
	rmb.metricSparkExecutorTime.emit(sm.Metrics())
	rmb.metricSparkJobStageActive.emit(sm.Metrics())
	rmb.metricSparkJobStageResult.emit(sm.Metrics())
	rmb.metricSparkJobTaskActive.emit(sm.Metrics())
	rmb.metricSparkJobTaskResult.emit(sm.Metrics())
	rmb.metricSparkStageDiskSpilled.emit(sm.Metrics())
	rmb.metricSparkStageExecutorCPUTime.emit(sm.Metrics())
	rmb.metricSparkStageExecutorRunTime.emit(sm.Metrics())
	rmb.metricSparkStageIoRecords.emit(sm.Metrics())
	rmb.metricSparkStageIoSize.emit(sm.Metrics())
	rmb.metricSparkStageJvmGcTime.emit(sm.Metrics())
	rmb.metricSparkStageMemoryPeak.emit(sm.Metrics())
	rmb.metricSparkStageMemorySpilled.emit(sm.Metrics())
	rmb.metricSparkStageShuffleBlocksFetched.emit(sm.Metrics())
	rmb.metricSparkStageShuffleFetchWaitTime.emit(sm.Metrics())
	rmb.metricSparkStageShuffleIoDisk.emit(sm.Metrics())
	rmb.metricSparkStageShuffleIoReadSize.emit(sm.Metrics())
	rmb.metricSparkStageShuffleIoRecords.emit(sm.Metrics())
	rmb.metricSparkStageShuffleIoWriteSize.emit(sm.Metrics())
	rmb.metricSparkStageShuffleWriteTime.emit(sm.Metrics())
	rmb.metricSparkStageStatus.emit(sm.Metrics())
	rmb.metricSparkStageTaskActive.emit(sm.Metrics())
	rmb.metricSparkStageTaskResult.emit(sm.Metrics())
	rmb.metricSparkStageTaskResultSize.emit(sm.Metrics())
	if sm.Metrics().Len() == 0 {
		return false
	}
	rmb.updateCapacity(sm.Metrics())
	sm.Scope().SetName("otelcol/apachesparkreceiver")
	sm.Scope().SetVersion(rmb.buildInfo.Version)
	rm := m.ResourceMetrics().AppendEmpty()
	rmb.resource.CopyTo(rm.Resource())
	sm.MoveTo(rm.ScopeMetrics().AppendEmpty())
	return true
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit() pmetric.Metrics {
	m := pmetric.NewMetrics()
	for _, rmb := range mb.rmbMap {
		if ok := rmb.emit(m); !ok {
			rmb.missedEmits++
		}
	}
	for k, rmb := range mb.rmbMap {
		if rmb.missedEmits >= missedEmitsToDropRMB {
			delete(mb.rmbMap, k)
		}
	}
	return m
}

// RecordSparkDriverBlockManagerDiskUsageDataPoint adds a data point to spark.driver.block_manager.disk.usage metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverBlockManagerDiskUsageDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverBlockManagerDiskUsage.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverBlockManagerMemoryUsageDataPoint adds a data point to spark.driver.block_manager.memory.usage metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverBlockManagerMemoryUsageDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation, stateAttributeValue AttributeState) {
	rmb.metricSparkDriverBlockManagerMemoryUsage.recordDataPoint(rmb.startTime, ts, val, locationAttributeValue.String(), stateAttributeValue.String())
}

// RecordSparkDriverCodeGeneratorCompilationAverageTimeDataPoint adds a data point to spark.driver.code_generator.compilation.average_time metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverCodeGeneratorCompilationAverageTimeDataPoint(ts pcommon.Timestamp, val float64) {
	rmb.metricSparkDriverCodeGeneratorCompilationAverageTime.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverCodeGeneratorCompilationCountDataPoint adds a data point to spark.driver.code_generator.compilation.count metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverCodeGeneratorCompilationCountDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverCodeGeneratorCompilationCount.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverCodeGeneratorGeneratedClassAverageSizeDataPoint adds a data point to spark.driver.code_generator.generated_class.average_size metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverCodeGeneratorGeneratedClassAverageSizeDataPoint(ts pcommon.Timestamp, val float64) {
	rmb.metricSparkDriverCodeGeneratorGeneratedClassAverageSize.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverCodeGeneratorGeneratedClassCountDataPoint adds a data point to spark.driver.code_generator.generated_class.count metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverCodeGeneratorGeneratedClassCountDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverCodeGeneratorGeneratedClassCount.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverCodeGeneratorGeneratedMethodAverageSizeDataPoint adds a data point to spark.driver.code_generator.generated_method.average_size metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverCodeGeneratorGeneratedMethodAverageSizeDataPoint(ts pcommon.Timestamp, val float64) {
	rmb.metricSparkDriverCodeGeneratorGeneratedMethodAverageSize.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverCodeGeneratorGeneratedMethodCountDataPoint adds a data point to spark.driver.code_generator.generated_method.count metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverCodeGeneratorGeneratedMethodCountDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverCodeGeneratorGeneratedMethodCount.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverCodeGeneratorSourceCodeAverageSizeDataPoint adds a data point to spark.driver.code_generator.source_code.average_size metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverCodeGeneratorSourceCodeAverageSizeDataPoint(ts pcommon.Timestamp, val float64) {
	rmb.metricSparkDriverCodeGeneratorSourceCodeAverageSize.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverCodeGeneratorSourceCodeOperationsDataPoint adds a data point to spark.driver.code_generator.source_code.operations metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverCodeGeneratorSourceCodeOperationsDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverCodeGeneratorSourceCodeOperations.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverDagSchedulerJobActiveDataPoint adds a data point to spark.driver.dag_scheduler.job.active metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverDagSchedulerJobActiveDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverDagSchedulerJobActive.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverDagSchedulerJobCountDataPoint adds a data point to spark.driver.dag_scheduler.job.count metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverDagSchedulerJobCountDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverDagSchedulerJobCount.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverDagSchedulerStageCountDataPoint adds a data point to spark.driver.dag_scheduler.stage.count metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverDagSchedulerStageCountDataPoint(ts pcommon.Timestamp, val int64, schedulerStatusAttributeValue AttributeSchedulerStatus) {
	rmb.metricSparkDriverDagSchedulerStageCount.recordDataPoint(rmb.startTime, ts, val, schedulerStatusAttributeValue.String())
}

// RecordSparkDriverDagSchedulerStageFailedDataPoint adds a data point to spark.driver.dag_scheduler.stage.failed metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverDagSchedulerStageFailedDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverDagSchedulerStageFailed.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverExecutorGcOperationsDataPoint adds a data point to spark.driver.executor.gc.operations metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverExecutorGcOperationsDataPoint(ts pcommon.Timestamp, val int64, gcTypeAttributeValue AttributeGcType) {
	rmb.metricSparkDriverExecutorGcOperations.recordDataPoint(rmb.startTime, ts, val, gcTypeAttributeValue.String())
}

// RecordSparkDriverExecutorGcTimeDataPoint adds a data point to spark.driver.executor.gc.time metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverExecutorGcTimeDataPoint(ts pcommon.Timestamp, val int64, gcTypeAttributeValue AttributeGcType) {
	rmb.metricSparkDriverExecutorGcTime.recordDataPoint(rmb.startTime, ts, val, gcTypeAttributeValue.String())
}

// RecordSparkDriverExecutorMemoryExecutionDataPoint adds a data point to spark.driver.executor.memory.execution metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverExecutorMemoryExecutionDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	rmb.metricSparkDriverExecutorMemoryExecution.recordDataPoint(rmb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkDriverExecutorMemoryJvmDataPoint adds a data point to spark.driver.executor.memory.jvm metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverExecutorMemoryJvmDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	rmb.metricSparkDriverExecutorMemoryJvm.recordDataPoint(rmb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkDriverExecutorMemoryPoolDataPoint adds a data point to spark.driver.executor.memory.pool metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverExecutorMemoryPoolDataPoint(ts pcommon.Timestamp, val int64, poolMemoryTypeAttributeValue AttributePoolMemoryType) {
	rmb.metricSparkDriverExecutorMemoryPool.recordDataPoint(rmb.startTime, ts, val, poolMemoryTypeAttributeValue.String())
}

// RecordSparkDriverExecutorMemoryStorageDataPoint adds a data point to spark.driver.executor.memory.storage metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverExecutorMemoryStorageDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	rmb.metricSparkDriverExecutorMemoryStorage.recordDataPoint(rmb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkDriverHiveExternalCatalogFileCacheHitsDataPoint adds a data point to spark.driver.hive_external_catalog.file_cache_hits metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverHiveExternalCatalogFileCacheHitsDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverHiveExternalCatalogFileCacheHits.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverHiveExternalCatalogFilesDiscoveredDataPoint adds a data point to spark.driver.hive_external_catalog.files_discovered metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverHiveExternalCatalogFilesDiscoveredDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverHiveExternalCatalogFilesDiscovered.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverHiveExternalCatalogHiveClientCallsDataPoint adds a data point to spark.driver.hive_external_catalog.hive_client_calls metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverHiveExternalCatalogHiveClientCallsDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverHiveExternalCatalogHiveClientCalls.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverHiveExternalCatalogParallelListingJobsDataPoint adds a data point to spark.driver.hive_external_catalog.parallel_listing_jobs metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverHiveExternalCatalogParallelListingJobsDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverHiveExternalCatalogParallelListingJobs.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverHiveExternalCatalogPartitionsFetchedDataPoint adds a data point to spark.driver.hive_external_catalog.partitions_fetched metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverHiveExternalCatalogPartitionsFetchedDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverHiveExternalCatalogPartitionsFetched.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverJvmCPUTimeDataPoint adds a data point to spark.driver.jvm_cpu_time metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverJvmCPUTimeDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverJvmCPUTime.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverLiveListenerBusDroppedDataPoint adds a data point to spark.driver.live_listener_bus.dropped metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverLiveListenerBusDroppedDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverLiveListenerBusDropped.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverLiveListenerBusPostedDataPoint adds a data point to spark.driver.live_listener_bus.posted metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverLiveListenerBusPostedDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverLiveListenerBusPosted.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverLiveListenerBusProcessingTimeAverageDataPoint adds a data point to spark.driver.live_listener_bus.processing_time.average metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverLiveListenerBusProcessingTimeAverageDataPoint(ts pcommon.Timestamp, val float64) {
	rmb.metricSparkDriverLiveListenerBusProcessingTimeAverage.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkDriverLiveListenerBusQueueSizeDataPoint adds a data point to spark.driver.live_listener_bus.queue_size metric.
func (rmb *ResourceMetricsBuilder) RecordSparkDriverLiveListenerBusQueueSizeDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkDriverLiveListenerBusQueueSize.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkExecutorDiskUsageDataPoint adds a data point to spark.executor.disk.usage metric.
func (rmb *ResourceMetricsBuilder) RecordSparkExecutorDiskUsageDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkExecutorDiskUsage.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkExecutorGcTimeDataPoint adds a data point to spark.executor.gc_time metric.
func (rmb *ResourceMetricsBuilder) RecordSparkExecutorGcTimeDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkExecutorGcTime.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkExecutorInputSizeDataPoint adds a data point to spark.executor.input_size metric.
func (rmb *ResourceMetricsBuilder) RecordSparkExecutorInputSizeDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkExecutorInputSize.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkExecutorMemoryUsageDataPoint adds a data point to spark.executor.memory.usage metric.
func (rmb *ResourceMetricsBuilder) RecordSparkExecutorMemoryUsageDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkExecutorMemoryUsage.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkExecutorShuffleIoSizeDataPoint adds a data point to spark.executor.shuffle.io.size metric.
func (rmb *ResourceMetricsBuilder) RecordSparkExecutorShuffleIoSizeDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	rmb.metricSparkExecutorShuffleIoSize.recordDataPoint(rmb.startTime, ts, val, directionAttributeValue.String())
}

// RecordSparkExecutorStorageMemoryUsageDataPoint adds a data point to spark.executor.storage_memory.usage metric.
func (rmb *ResourceMetricsBuilder) RecordSparkExecutorStorageMemoryUsageDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation, stateAttributeValue AttributeState) {
	rmb.metricSparkExecutorStorageMemoryUsage.recordDataPoint(rmb.startTime, ts, val, locationAttributeValue.String(), stateAttributeValue.String())
}

// RecordSparkExecutorTaskActiveDataPoint adds a data point to spark.executor.task.active metric.
func (rmb *ResourceMetricsBuilder) RecordSparkExecutorTaskActiveDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkExecutorTaskActive.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkExecutorTaskLimitDataPoint adds a data point to spark.executor.task.limit metric.
func (rmb *ResourceMetricsBuilder) RecordSparkExecutorTaskLimitDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkExecutorTaskLimit.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkExecutorTaskResultDataPoint adds a data point to spark.executor.task.result metric.
func (rmb *ResourceMetricsBuilder) RecordSparkExecutorTaskResultDataPoint(ts pcommon.Timestamp, val int64, executorTaskResultAttributeValue AttributeExecutorTaskResult) {
	rmb.metricSparkExecutorTaskResult.recordDataPoint(rmb.startTime, ts, val, executorTaskResultAttributeValue.String())
}

// RecordSparkExecutorTimeDataPoint adds a data point to spark.executor.time metric.
func (rmb *ResourceMetricsBuilder) RecordSparkExecutorTimeDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkExecutorTime.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkJobStageActiveDataPoint adds a data point to spark.job.stage.active metric.
func (rmb *ResourceMetricsBuilder) RecordSparkJobStageActiveDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkJobStageActive.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkJobStageResultDataPoint adds a data point to spark.job.stage.result metric.
func (rmb *ResourceMetricsBuilder) RecordSparkJobStageResultDataPoint(ts pcommon.Timestamp, val int64, jobResultAttributeValue AttributeJobResult) {
	rmb.metricSparkJobStageResult.recordDataPoint(rmb.startTime, ts, val, jobResultAttributeValue.String())
}

// RecordSparkJobTaskActiveDataPoint adds a data point to spark.job.task.active metric.
func (rmb *ResourceMetricsBuilder) RecordSparkJobTaskActiveDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkJobTaskActive.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkJobTaskResultDataPoint adds a data point to spark.job.task.result metric.
func (rmb *ResourceMetricsBuilder) RecordSparkJobTaskResultDataPoint(ts pcommon.Timestamp, val int64, jobResultAttributeValue AttributeJobResult) {
	rmb.metricSparkJobTaskResult.recordDataPoint(rmb.startTime, ts, val, jobResultAttributeValue.String())
}

// RecordSparkStageDiskSpilledDataPoint adds a data point to spark.stage.disk.spilled metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageDiskSpilledDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkStageDiskSpilled.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkStageExecutorCPUTimeDataPoint adds a data point to spark.stage.executor.cpu_time metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageExecutorCPUTimeDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkStageExecutorCPUTime.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkStageExecutorRunTimeDataPoint adds a data point to spark.stage.executor.run_time metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageExecutorRunTimeDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkStageExecutorRunTime.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkStageIoRecordsDataPoint adds a data point to spark.stage.io.records metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageIoRecordsDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	rmb.metricSparkStageIoRecords.recordDataPoint(rmb.startTime, ts, val, directionAttributeValue.String())
}

// RecordSparkStageIoSizeDataPoint adds a data point to spark.stage.io.size metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageIoSizeDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	rmb.metricSparkStageIoSize.recordDataPoint(rmb.startTime, ts, val, directionAttributeValue.String())
}

// RecordSparkStageJvmGcTimeDataPoint adds a data point to spark.stage.jvm_gc_time metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageJvmGcTimeDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkStageJvmGcTime.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkStageMemoryPeakDataPoint adds a data point to spark.stage.memory.peak metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageMemoryPeakDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkStageMemoryPeak.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkStageMemorySpilledDataPoint adds a data point to spark.stage.memory.spilled metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageMemorySpilledDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkStageMemorySpilled.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkStageShuffleBlocksFetchedDataPoint adds a data point to spark.stage.shuffle.blocks_fetched metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageShuffleBlocksFetchedDataPoint(ts pcommon.Timestamp, val int64, sourceAttributeValue AttributeSource) {
	rmb.metricSparkStageShuffleBlocksFetched.recordDataPoint(rmb.startTime, ts, val, sourceAttributeValue.String())
}

// RecordSparkStageShuffleFetchWaitTimeDataPoint adds a data point to spark.stage.shuffle.fetch_wait_time metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageShuffleFetchWaitTimeDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkStageShuffleFetchWaitTime.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkStageShuffleIoDiskDataPoint adds a data point to spark.stage.shuffle.io.disk metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageShuffleIoDiskDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkStageShuffleIoDisk.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkStageShuffleIoReadSizeDataPoint adds a data point to spark.stage.shuffle.io.read.size metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageShuffleIoReadSizeDataPoint(ts pcommon.Timestamp, val int64, sourceAttributeValue AttributeSource) {
	rmb.metricSparkStageShuffleIoReadSize.recordDataPoint(rmb.startTime, ts, val, sourceAttributeValue.String())
}

// RecordSparkStageShuffleIoRecordsDataPoint adds a data point to spark.stage.shuffle.io.records metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageShuffleIoRecordsDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	rmb.metricSparkStageShuffleIoRecords.recordDataPoint(rmb.startTime, ts, val, directionAttributeValue.String())
}

// RecordSparkStageShuffleIoWriteSizeDataPoint adds a data point to spark.stage.shuffle.io.write.size metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageShuffleIoWriteSizeDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkStageShuffleIoWriteSize.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkStageShuffleWriteTimeDataPoint adds a data point to spark.stage.shuffle.write_time metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageShuffleWriteTimeDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkStageShuffleWriteTime.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkStageStatusDataPoint adds a data point to spark.stage.status metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageStatusDataPoint(ts pcommon.Timestamp, val int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	rmb.metricSparkStageStatus.recordDataPoint(rmb.startTime, ts, val, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageTaskActiveDataPoint adds a data point to spark.stage.task.active metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageTaskActiveDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkStageTaskActive.recordDataPoint(rmb.startTime, ts, val)
}

// RecordSparkStageTaskResultDataPoint adds a data point to spark.stage.task.result metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageTaskResultDataPoint(ts pcommon.Timestamp, val int64, stageTaskResultAttributeValue AttributeStageTaskResult) {
	rmb.metricSparkStageTaskResult.recordDataPoint(rmb.startTime, ts, val, stageTaskResultAttributeValue.String())
}

// RecordSparkStageTaskResultSizeDataPoint adds a data point to spark.stage.task.result_size metric.
func (rmb *ResourceMetricsBuilder) RecordSparkStageTaskResultSizeDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricSparkStageTaskResultSize.recordDataPoint(rmb.startTime, ts, val)
}

// Reset resets the ResourceMetricsBuilder to its initial state. It should be used when external metrics source is
// restarted, and the ResourceMetricsBuilder should update its startTime and reset it's internal state accordingly.
func (rmb *ResourceMetricsBuilder) Reset(options ...resourceMetricsBuilderOption) {
	rmb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(rmb)
	}
}
