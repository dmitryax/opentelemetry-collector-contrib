// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"fmt"
	"strconv"
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"

	"github.com/open-telemetry/opentelemetry-collector-contrib/pkg/pdatautil"
)

// AttributeCPULevel specifies the a value cpu_level attribute.
type AttributeCPULevel int

const (
	_ AttributeCPULevel = iota
	AttributeCPULevelSelf
	AttributeCPULevelChildren
)

// String returns the string representation of the AttributeCPULevel.
func (av AttributeCPULevel) String() string {
	switch av {
	case AttributeCPULevelSelf:
		return "self"
	case AttributeCPULevelChildren:
		return "children"
	}
	return ""
}

// MapAttributeCPULevel is a helper map of string to AttributeCPULevel attribute value.
var MapAttributeCPULevel = map[string]AttributeCPULevel{
	"self":     AttributeCPULevelSelf,
	"children": AttributeCPULevelChildren,
}

// AttributeCPUMode specifies the a value cpu_mode attribute.
type AttributeCPUMode int

const (
	_ AttributeCPUMode = iota
	AttributeCPUModeSystem
	AttributeCPUModeUser
)

// String returns the string representation of the AttributeCPUMode.
func (av AttributeCPUMode) String() string {
	switch av {
	case AttributeCPUModeSystem:
		return "system"
	case AttributeCPUModeUser:
		return "user"
	}
	return ""
}

// MapAttributeCPUMode is a helper map of string to AttributeCPUMode attribute value.
var MapAttributeCPUMode = map[string]AttributeCPUMode{
	"system": AttributeCPUModeSystem,
	"user":   AttributeCPUModeUser,
}

// AttributeScoreboardState specifies the a value scoreboard_state attribute.
type AttributeScoreboardState int

const (
	_ AttributeScoreboardState = iota
	AttributeScoreboardStateOpen
	AttributeScoreboardStateWaiting
	AttributeScoreboardStateStarting
	AttributeScoreboardStateReading
	AttributeScoreboardStateSending
	AttributeScoreboardStateKeepalive
	AttributeScoreboardStateDnslookup
	AttributeScoreboardStateClosing
	AttributeScoreboardStateLogging
	AttributeScoreboardStateFinishing
	AttributeScoreboardStateIdleCleanup
	AttributeScoreboardStateUnknown
)

// String returns the string representation of the AttributeScoreboardState.
func (av AttributeScoreboardState) String() string {
	switch av {
	case AttributeScoreboardStateOpen:
		return "open"
	case AttributeScoreboardStateWaiting:
		return "waiting"
	case AttributeScoreboardStateStarting:
		return "starting"
	case AttributeScoreboardStateReading:
		return "reading"
	case AttributeScoreboardStateSending:
		return "sending"
	case AttributeScoreboardStateKeepalive:
		return "keepalive"
	case AttributeScoreboardStateDnslookup:
		return "dnslookup"
	case AttributeScoreboardStateClosing:
		return "closing"
	case AttributeScoreboardStateLogging:
		return "logging"
	case AttributeScoreboardStateFinishing:
		return "finishing"
	case AttributeScoreboardStateIdleCleanup:
		return "idle_cleanup"
	case AttributeScoreboardStateUnknown:
		return "unknown"
	}
	return ""
}

// MapAttributeScoreboardState is a helper map of string to AttributeScoreboardState attribute value.
var MapAttributeScoreboardState = map[string]AttributeScoreboardState{
	"open":         AttributeScoreboardStateOpen,
	"waiting":      AttributeScoreboardStateWaiting,
	"starting":     AttributeScoreboardStateStarting,
	"reading":      AttributeScoreboardStateReading,
	"sending":      AttributeScoreboardStateSending,
	"keepalive":    AttributeScoreboardStateKeepalive,
	"dnslookup":    AttributeScoreboardStateDnslookup,
	"closing":      AttributeScoreboardStateClosing,
	"logging":      AttributeScoreboardStateLogging,
	"finishing":    AttributeScoreboardStateFinishing,
	"idle_cleanup": AttributeScoreboardStateIdleCleanup,
	"unknown":      AttributeScoreboardStateUnknown,
}

// AttributeWorkersState specifies the a value workers_state attribute.
type AttributeWorkersState int

const (
	_ AttributeWorkersState = iota
	AttributeWorkersStateBusy
	AttributeWorkersStateIdle
)

// String returns the string representation of the AttributeWorkersState.
func (av AttributeWorkersState) String() string {
	switch av {
	case AttributeWorkersStateBusy:
		return "busy"
	case AttributeWorkersStateIdle:
		return "idle"
	}
	return ""
}

// MapAttributeWorkersState is a helper map of string to AttributeWorkersState attribute value.
var MapAttributeWorkersState = map[string]AttributeWorkersState{
	"busy": AttributeWorkersStateBusy,
	"idle": AttributeWorkersStateIdle,
}

type metricApacheCPULoad struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills apache.cpu.load metric with initial data.
func (m *metricApacheCPULoad) init() {
	m.data.SetName("apache.cpu.load")
	m.data.SetDescription("Current load of the CPU.")
	m.data.SetUnit("%")
	m.data.SetEmptyGauge()
}

func (m *metricApacheCPULoad) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricApacheCPULoad) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricApacheCPULoad) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricApacheCPULoad(cfg MetricConfig) metricApacheCPULoad {
	m := metricApacheCPULoad{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricApacheCPUTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills apache.cpu.time metric with initial data.
func (m *metricApacheCPUTime) init() {
	m.data.SetName("apache.cpu.time")
	m.data.SetDescription("Jiffs used by processes of given category.")
	m.data.SetUnit("{jiff}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricApacheCPUTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, cpuLevelAttributeValue string, cpuModeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("level", cpuLevelAttributeValue)
	dp.Attributes().PutStr("mode", cpuModeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricApacheCPUTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricApacheCPUTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricApacheCPUTime(cfg MetricConfig) metricApacheCPUTime {
	m := metricApacheCPUTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricApacheCurrentConnections struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills apache.current_connections metric with initial data.
func (m *metricApacheCurrentConnections) init() {
	m.data.SetName("apache.current_connections")
	m.data.SetDescription("The number of active connections currently attached to the HTTP server.")
	m.data.SetUnit("{connections}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricApacheCurrentConnections) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricApacheCurrentConnections) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricApacheCurrentConnections) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricApacheCurrentConnections(cfg MetricConfig) metricApacheCurrentConnections {
	m := metricApacheCurrentConnections{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricApacheLoad1 struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills apache.load.1 metric with initial data.
func (m *metricApacheLoad1) init() {
	m.data.SetName("apache.load.1")
	m.data.SetDescription("The average server load during the last minute.")
	m.data.SetUnit("%")
	m.data.SetEmptyGauge()
}

func (m *metricApacheLoad1) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricApacheLoad1) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricApacheLoad1) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricApacheLoad1(cfg MetricConfig) metricApacheLoad1 {
	m := metricApacheLoad1{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricApacheLoad15 struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills apache.load.15 metric with initial data.
func (m *metricApacheLoad15) init() {
	m.data.SetName("apache.load.15")
	m.data.SetDescription("The average server load during the last 15 minutes.")
	m.data.SetUnit("%")
	m.data.SetEmptyGauge()
}

func (m *metricApacheLoad15) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricApacheLoad15) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricApacheLoad15) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricApacheLoad15(cfg MetricConfig) metricApacheLoad15 {
	m := metricApacheLoad15{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricApacheLoad5 struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills apache.load.5 metric with initial data.
func (m *metricApacheLoad5) init() {
	m.data.SetName("apache.load.5")
	m.data.SetDescription("The average server load during the last 5 minutes.")
	m.data.SetUnit("%")
	m.data.SetEmptyGauge()
}

func (m *metricApacheLoad5) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricApacheLoad5) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricApacheLoad5) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricApacheLoad5(cfg MetricConfig) metricApacheLoad5 {
	m := metricApacheLoad5{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricApacheRequestTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills apache.request.time metric with initial data.
func (m *metricApacheRequestTime) init() {
	m.data.SetName("apache.request.time")
	m.data.SetDescription("Total time spent on handling requests.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricApacheRequestTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricApacheRequestTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricApacheRequestTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricApacheRequestTime(cfg MetricConfig) metricApacheRequestTime {
	m := metricApacheRequestTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricApacheRequests struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills apache.requests metric with initial data.
func (m *metricApacheRequests) init() {
	m.data.SetName("apache.requests")
	m.data.SetDescription("The number of requests serviced by the HTTP server per second.")
	m.data.SetUnit("{requests}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricApacheRequests) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricApacheRequests) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricApacheRequests) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricApacheRequests(cfg MetricConfig) metricApacheRequests {
	m := metricApacheRequests{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricApacheScoreboard struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills apache.scoreboard metric with initial data.
func (m *metricApacheScoreboard) init() {
	m.data.SetName("apache.scoreboard")
	m.data.SetDescription("The number of workers in each state.")
	m.data.SetUnit("{workers}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricApacheScoreboard) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, scoreboardStateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("state", scoreboardStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricApacheScoreboard) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricApacheScoreboard) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricApacheScoreboard(cfg MetricConfig) metricApacheScoreboard {
	m := metricApacheScoreboard{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricApacheTraffic struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills apache.traffic metric with initial data.
func (m *metricApacheTraffic) init() {
	m.data.SetName("apache.traffic")
	m.data.SetDescription("Total HTTP server traffic.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricApacheTraffic) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricApacheTraffic) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricApacheTraffic) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricApacheTraffic(cfg MetricConfig) metricApacheTraffic {
	m := metricApacheTraffic{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricApacheUptime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills apache.uptime metric with initial data.
func (m *metricApacheUptime) init() {
	m.data.SetName("apache.uptime")
	m.data.SetDescription("The amount of time that the server has been running in seconds.")
	m.data.SetUnit("s")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricApacheUptime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricApacheUptime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricApacheUptime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricApacheUptime(cfg MetricConfig) metricApacheUptime {
	m := metricApacheUptime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricApacheWorkers struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills apache.workers metric with initial data.
func (m *metricApacheWorkers) init() {
	m.data.SetName("apache.workers")
	m.data.SetDescription("The number of workers currently attached to the HTTP server.")
	m.data.SetUnit("{workers}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricApacheWorkers) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, workersStateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("state", workersStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricApacheWorkers) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricApacheWorkers) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricApacheWorkers(cfg MetricConfig) metricApacheWorkers {
	m := metricApacheWorkers{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// missedEmitsToDropRMB is number of missed emits after which resource builder will be dropped from MetricsBuilder.rmbMap.
// Potentially, this value can be made configurable through a MetricsBuilder option.
const missedEmitsToDropRMB = 5

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config    MetricsBuilderConfig                 // config of the metrics builder.
	buildInfo component.BuildInfo                  // contains version information
	startTime pcommon.Timestamp                    // start time that will be applied to all recorded data points.
	rmbMap    map[[16]byte]*ResourceMetricsBuilder // map of resource builders by resource hash.
}

type ResourceMetricsBuilder struct {
	buildInfo                      component.BuildInfo
	startTime                      pcommon.Timestamp // start time that will be applied to all recorded data points.
	metricsCapacity                int               // maximum observed number of metrics per resource.
	resource                       pcommon.Resource
	missedEmits                    int
	metricApacheCPULoad            metricApacheCPULoad
	metricApacheCPUTime            metricApacheCPUTime
	metricApacheCurrentConnections metricApacheCurrentConnections
	metricApacheLoad1              metricApacheLoad1
	metricApacheLoad15             metricApacheLoad15
	metricApacheLoad5              metricApacheLoad5
	metricApacheRequestTime        metricApacheRequestTime
	metricApacheRequests           metricApacheRequests
	metricApacheScoreboard         metricApacheScoreboard
	metricApacheTraffic            metricApacheTraffic
	metricApacheUptime             metricApacheUptime
	metricApacheWorkers            metricApacheWorkers
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.CreateSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:    mbc,
		startTime: pcommon.NewTimestampFromTime(time.Now()),
		buildInfo: settings.BuildInfo,
		rmbMap:    make(map[[16]byte]*ResourceMetricsBuilder),
	}
	for _, opt := range options {
		opt(mb)
	}
	return mb
}

// resourceMetricsBuilderOption applies changes to provided resource metrics.
type resourceMetricsBuilderOption func(*ResourceMetricsBuilder)

// WithStartTimeOverride sets start time for all the resource metrics data points.
func WithStartTimeOverride(start pcommon.Timestamp) resourceMetricsBuilderOption {
	return func(rmb *ResourceMetricsBuilder) {
		rmb.startTime = start
	}
}

// ResourceMetricsBuilder returns a ResourceMetricsBuilder that can be used to record metrics for a specific resource.
// It requires Resource to be provided which should be built with ResourceBuilder.
func (mb *MetricsBuilder) ResourceMetricsBuilder(res pcommon.Resource, options ...resourceMetricsBuilderOption) *ResourceMetricsBuilder {
	hash := pdatautil.MapHash(res.Attributes())
	if rmb, ok := mb.rmbMap[hash]; ok {
		return rmb
	}
	rmb := &ResourceMetricsBuilder{
		startTime:                      mb.startTime,
		buildInfo:                      mb.buildInfo,
		resource:                       res,
		metricApacheCPULoad:            newMetricApacheCPULoad(mb.config.Metrics.ApacheCPULoad),
		metricApacheCPUTime:            newMetricApacheCPUTime(mb.config.Metrics.ApacheCPUTime),
		metricApacheCurrentConnections: newMetricApacheCurrentConnections(mb.config.Metrics.ApacheCurrentConnections),
		metricApacheLoad1:              newMetricApacheLoad1(mb.config.Metrics.ApacheLoad1),
		metricApacheLoad15:             newMetricApacheLoad15(mb.config.Metrics.ApacheLoad15),
		metricApacheLoad5:              newMetricApacheLoad5(mb.config.Metrics.ApacheLoad5),
		metricApacheRequestTime:        newMetricApacheRequestTime(mb.config.Metrics.ApacheRequestTime),
		metricApacheRequests:           newMetricApacheRequests(mb.config.Metrics.ApacheRequests),
		metricApacheScoreboard:         newMetricApacheScoreboard(mb.config.Metrics.ApacheScoreboard),
		metricApacheTraffic:            newMetricApacheTraffic(mb.config.Metrics.ApacheTraffic),
		metricApacheUptime:             newMetricApacheUptime(mb.config.Metrics.ApacheUptime),
		metricApacheWorkers:            newMetricApacheWorkers(mb.config.Metrics.ApacheWorkers),
	}
	for _, op := range options {
		op(rmb)
	}
	mb.rmbMap[hash] = rmb
	return rmb
}

// NewResourceBuilder returns a new resource builder that should be used to build a resource associated with for the emitted metrics.
func (mb *MetricsBuilder) NewResourceBuilder() *ResourceBuilder {
	return NewResourceBuilder(mb.config.ResourceAttributes)
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (rmb *ResourceMetricsBuilder) updateCapacity(ms pmetric.MetricSlice) {
	if rmb.metricsCapacity < ms.Len() {
		rmb.metricsCapacity = ms.Len()
	}
}

// emit emits all the metrics accumulated by the ResourceMetricsBuilder and updates the internal state to be ready for
// recording another set of metrics. It returns true if any metrics were emitted.
func (rmb *ResourceMetricsBuilder) emit(m pmetric.Metrics) bool {
	sm := pmetric.NewScopeMetrics()
	sm.Metrics().EnsureCapacity(rmb.metricsCapacity)
	rmb.metricApacheCPULoad.emit(sm.Metrics())
	rmb.metricApacheCPUTime.emit(sm.Metrics())
	rmb.metricApacheCurrentConnections.emit(sm.Metrics())
	rmb.metricApacheLoad1.emit(sm.Metrics())
	rmb.metricApacheLoad15.emit(sm.Metrics())
	rmb.metricApacheLoad5.emit(sm.Metrics())
	rmb.metricApacheRequestTime.emit(sm.Metrics())
	rmb.metricApacheRequests.emit(sm.Metrics())
	rmb.metricApacheScoreboard.emit(sm.Metrics())
	rmb.metricApacheTraffic.emit(sm.Metrics())
	rmb.metricApacheUptime.emit(sm.Metrics())
	rmb.metricApacheWorkers.emit(sm.Metrics())
	if sm.Metrics().Len() == 0 {
		return false
	}
	rmb.updateCapacity(sm.Metrics())
	sm.Scope().SetName("otelcol/apachereceiver")
	sm.Scope().SetVersion(rmb.buildInfo.Version)
	rm := m.ResourceMetrics().AppendEmpty()
	rmb.resource.CopyTo(rm.Resource())
	sm.MoveTo(rm.ScopeMetrics().AppendEmpty())
	return true
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit() pmetric.Metrics {
	m := pmetric.NewMetrics()
	for _, rmb := range mb.rmbMap {
		if ok := rmb.emit(m); !ok {
			rmb.missedEmits++
		}
	}
	for k, rmb := range mb.rmbMap {
		if rmb.missedEmits >= missedEmitsToDropRMB {
			delete(mb.rmbMap, k)
		}
	}
	return m
}

// RecordApacheCPULoadDataPoint adds a data point to apache.cpu.load metric.
func (rmb *ResourceMetricsBuilder) RecordApacheCPULoadDataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseFloat(inputVal, 64)
	if err != nil {
		return fmt.Errorf("failed to parse float64 for ApacheCPULoad, value was %s: %w", inputVal, err)
	}
	rmb.metricApacheCPULoad.recordDataPoint(rmb.startTime, ts, val)
	return nil
}

// RecordApacheCPUTimeDataPoint adds a data point to apache.cpu.time metric.
func (rmb *ResourceMetricsBuilder) RecordApacheCPUTimeDataPoint(ts pcommon.Timestamp, inputVal string, cpuLevelAttributeValue AttributeCPULevel, cpuModeAttributeValue AttributeCPUMode) error {
	val, err := strconv.ParseFloat(inputVal, 64)
	if err != nil {
		return fmt.Errorf("failed to parse float64 for ApacheCPUTime, value was %s: %w", inputVal, err)
	}
	rmb.metricApacheCPUTime.recordDataPoint(rmb.startTime, ts, val, cpuLevelAttributeValue.String(), cpuModeAttributeValue.String())
	return nil
}

// RecordApacheCurrentConnectionsDataPoint adds a data point to apache.current_connections metric.
func (rmb *ResourceMetricsBuilder) RecordApacheCurrentConnectionsDataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for ApacheCurrentConnections, value was %s: %w", inputVal, err)
	}
	rmb.metricApacheCurrentConnections.recordDataPoint(rmb.startTime, ts, val)
	return nil
}

// RecordApacheLoad1DataPoint adds a data point to apache.load.1 metric.
func (rmb *ResourceMetricsBuilder) RecordApacheLoad1DataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseFloat(inputVal, 64)
	if err != nil {
		return fmt.Errorf("failed to parse float64 for ApacheLoad1, value was %s: %w", inputVal, err)
	}
	rmb.metricApacheLoad1.recordDataPoint(rmb.startTime, ts, val)
	return nil
}

// RecordApacheLoad15DataPoint adds a data point to apache.load.15 metric.
func (rmb *ResourceMetricsBuilder) RecordApacheLoad15DataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseFloat(inputVal, 64)
	if err != nil {
		return fmt.Errorf("failed to parse float64 for ApacheLoad15, value was %s: %w", inputVal, err)
	}
	rmb.metricApacheLoad15.recordDataPoint(rmb.startTime, ts, val)
	return nil
}

// RecordApacheLoad5DataPoint adds a data point to apache.load.5 metric.
func (rmb *ResourceMetricsBuilder) RecordApacheLoad5DataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseFloat(inputVal, 64)
	if err != nil {
		return fmt.Errorf("failed to parse float64 for ApacheLoad5, value was %s: %w", inputVal, err)
	}
	rmb.metricApacheLoad5.recordDataPoint(rmb.startTime, ts, val)
	return nil
}

// RecordApacheRequestTimeDataPoint adds a data point to apache.request.time metric.
func (rmb *ResourceMetricsBuilder) RecordApacheRequestTimeDataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for ApacheRequestTime, value was %s: %w", inputVal, err)
	}
	rmb.metricApacheRequestTime.recordDataPoint(rmb.startTime, ts, val)
	return nil
}

// RecordApacheRequestsDataPoint adds a data point to apache.requests metric.
func (rmb *ResourceMetricsBuilder) RecordApacheRequestsDataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for ApacheRequests, value was %s: %w", inputVal, err)
	}
	rmb.metricApacheRequests.recordDataPoint(rmb.startTime, ts, val)
	return nil
}

// RecordApacheScoreboardDataPoint adds a data point to apache.scoreboard metric.
func (rmb *ResourceMetricsBuilder) RecordApacheScoreboardDataPoint(ts pcommon.Timestamp, val int64, scoreboardStateAttributeValue AttributeScoreboardState) {
	rmb.metricApacheScoreboard.recordDataPoint(rmb.startTime, ts, val, scoreboardStateAttributeValue.String())
}

// RecordApacheTrafficDataPoint adds a data point to apache.traffic metric.
func (rmb *ResourceMetricsBuilder) RecordApacheTrafficDataPoint(ts pcommon.Timestamp, val int64) {
	rmb.metricApacheTraffic.recordDataPoint(rmb.startTime, ts, val)
}

// RecordApacheUptimeDataPoint adds a data point to apache.uptime metric.
func (rmb *ResourceMetricsBuilder) RecordApacheUptimeDataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for ApacheUptime, value was %s: %w", inputVal, err)
	}
	rmb.metricApacheUptime.recordDataPoint(rmb.startTime, ts, val)
	return nil
}

// RecordApacheWorkersDataPoint adds a data point to apache.workers metric.
func (rmb *ResourceMetricsBuilder) RecordApacheWorkersDataPoint(ts pcommon.Timestamp, inputVal string, workersStateAttributeValue AttributeWorkersState) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for ApacheWorkers, value was %s: %w", inputVal, err)
	}
	rmb.metricApacheWorkers.recordDataPoint(rmb.startTime, ts, val, workersStateAttributeValue.String())
	return nil
}

// Reset resets the ResourceMetricsBuilder to its initial state. It should be used when external metrics source is
// restarted, and the ResourceMetricsBuilder should update its startTime and reset it's internal state accordingly.
func (rmb *ResourceMetricsBuilder) Reset(options ...resourceMetricsBuilderOption) {
	rmb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(rmb)
	}
}
